{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75330dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581544f1",
   "metadata": {},
   "source": [
    "# Hunting for dark matter in LUX-ZEPLIN\n",
    "\n",
    "Only about 15% of the matter in the universe is composed of particles (electrons, protons, etc.) that scientists have been able to study in great detail. The other 85% is composed of an unknown, \"dark\" matter that can interact gravitationally, but whose other kinds of interactions aren't well understood.\n",
    "\n",
    "There are a few different ways scientists can probe those other interactions of dark matter. Detectors like the LUX-ZEPLIN (LZ) detector below hope to \"directly detect\" dark matter by looking for rare scatters of dark matter particles on a target material. In LZ's case, a dark matter particle might very rarely smack into an atomic nucleus of one of the atoms within the detector (specifically, xenon). This produces flashes of light that can be detected, a so-called \"S1\" and \"S2.\" The presence of one or both of these tells us that we have seen an interaction, or <b>\"event\"</b> occur within our detector volume.\n",
    "\n",
    "<img src=\"figures/LZDetector.png\" width=\"400\"/>\n",
    "\n",
    "\n",
    "However, just because we see an event, it doesn't mean we're certainly seeing dark matter interact. For example, an S1+S2 may instead be created by a random interaction of an ambient $\\gamma$ ray (high energy photon) hitting our xenon atoms. So to search for dark matter interactions, it is first important to understand the difference between those so-called \"background\" events, and so-called \"signal\" events:\n",
    "\n",
    "\n",
    "\n",
    "<b>Background:</b> These are events from known physics, that may mimic dark matter. Examples: $\\gamma$-ray interactions, $\\beta$ interactions, etc. Think of these as \"boring\" events, which we don't care about seeing.\n",
    "\n",
    "<b>Signal:</b> These are possible dark matter or other \"new physics\" events. These are \"interesting\" events.\n",
    "\n",
    "\n",
    "In LZ, signal and background events have different detection signatures that allow us to distinguish whether an event is due to signal or background. For example, S2s of background events are slightly more bright than S2s of signal events, because $\\gamma$s and $\\beta$s tend to smack into the atomic charge cloud instead of the xenon nucleus.\n",
    "\n",
    "However, because the details of how the interactions create the S1 and S2 are messy, we cannot <i>perfectly</i> distinguish whether an individual event is signal or background. In other words, there's some fraction of background events that look more like signal events, and some fraction of signal events that look more like background events. This situation, where signal and backgrounds bleed together to some degree, is extremely common in event-based experiments. In this lab, we will explore the analysis methods used to do searches for rare signals under such conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f739a62",
   "metadata": {},
   "source": [
    "# !! Note: careful with time usage.\n",
    "\n",
    "In this lab, we'll ask you some qualitative and quantitative questions about statistical methods for dark matter searches. Many of these can be answered in a single sentence or even a single number, so don't overthink them. Having enough time for the second lab this week is very important!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131fd1eb",
   "metadata": {},
   "source": [
    "# Gathering Calibration Data\n",
    "First, let's get a sense of what background data looks like. One way to get a sense of what background gamma or beta events look like is to do a calibration with some known $\\beta$ source. Let's load in 100,000 events from a $\\beta$ calibration source, and look at the sizes of the S2 flashes. There's a good deal of spread in these S2 sizes, so we typically look at the logarithm of the S2 size instead of the size itself, i.e. Log(S2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46afa668",
   "metadata": {},
   "outputs": [],
   "source": [
    "backgroundlike_calibration_data = np.loadtxt(open(\"../data/background_calibration_data.txt\",'r'))\n",
    "\n",
    "\n",
    "#Take the S2 values from the background-like calibration data and plot in a histogram. Each line is one event\n",
    "backgroundlike_logS2Bins = np.linspace(0.5,5,100)\n",
    "backgroundlike_logS2 = np.log10(backgroundlike_calibration_data[:])\n",
    "\n",
    "#Plot these events \n",
    "_ = plt.hist(backgroundlike_logS2, bins=backgroundlike_logS2Bins,fc=(0, 0, 1, 0.3),label=\"background-like events\")\n",
    "_ = plt.xlabel(r'Log(S2 size)')\n",
    "_ = plt.ylabel(r'Counts per bin')\n",
    "_ = plt.yscale('log')\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b813d671",
   "metadata": {},
   "source": [
    "Now, let's try to get a sense of what signal-like data will look like. As mentioned above, we expect dark matter scatters to look a bit different than $\\gamma$ or $\\beta$ scatters. Since humans haven't yet detected dark matter, we can't calibrate <i>with</i> real dark matter scatters. However, neutrons also smack into the nucleus of the atom, so we can shoot some neutrons into our detector to get a \"signal-like\" calibration dataset. Let's load in 100,000 of those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b0729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in the neutron (signal-like) calibration events\n",
    "signallike_calibration_data = np.loadtxt(open(\"../data/neutron_calibration_data.txt\",'r'))\n",
    "\n",
    "#Plot these on the same axes as the background-like calibration data\n",
    "signallike_logS2 = np.log10(signallike_calibration_data[:])\n",
    "_ = plt.hist(backgroundlike_logS2, bins=backgroundlike_logS2Bins,fc=(0, 0, 1, 0.3),label=\"background-like events\")\n",
    "_ = plt.hist(signallike_logS2, bins=backgroundlike_logS2Bins,fc=(1, 0, 0, 0.3),label=\"signal-like events\")\n",
    "_ = plt.xlabel(r'Log(S2 size)')\n",
    "_ = plt.ylabel(r'Counts per bin')\n",
    "_ = plt.yscale('log')\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685db44d",
   "metadata": {},
   "source": [
    "# Questions for Discussion\n",
    "1.1 What are we plotting in the above two plots? What does an individual entry in the blue histogram represent? What does an individual entry in the red histogram represent?\n",
    "\n",
    "1.2 The peaks of the two histograms are separated in Log(S2) space. What does this separation mean for our ability to distinguish background-like ($\\beta$) events from signal-like (neutron) events?\n",
    "\n",
    "1.3 What do the widths of the two histograms mean? What does it mean that the histograms overlap a little bit? <b>Hint</b>: this overlap is what was previously referred to as \"bleed\" in the opening paragraph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8673a7",
   "metadata": {},
   "source": [
    "# Defining a background cut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7e07e3",
   "metadata": {},
   "source": [
    "Now we want to use these calibration datasets to come up with a \"cut\" to remove events that we know are extremely likely to be background-like. For simplicity, let's just cut away all events with Log(S2) above a certain value $X_{c}$. An example is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b327fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function we use to help us cut away events with S2s above a certain threshold cutVal\n",
    "def CutEvents(eventList,cutVal):\n",
    "    \n",
    "    #Sort events by Log(S2) to make the cut easier\n",
    "    cutEventList = eventList\n",
    "    cutEventList.sort()\n",
    "    \n",
    "    #Loop through elements and remove those above the cut value\n",
    "    counter = 0\n",
    "    for event in cutEventList:\n",
    "        if(event > cutVal):\n",
    "            cutEventList = np.delete(cutEventList,np.s_[counter:])\n",
    "            break\n",
    "        counter = counter + 1\n",
    "    \n",
    "    return cutEventList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b36fe53",
   "metadata": {},
   "source": [
    "<b>Note:</b> to change the cut value, you can modify the variable \"cutValue_Xc\" below. (You'll need to do this anyway for the next few questions!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eecc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a cut value - play with this!\n",
    "cutValue_Xc = 3.1\n",
    "\n",
    "\n",
    "#Loop through elements and remove those above the cut value\n",
    "signallike_logS2_afterCut = CutEvents(signallike_logS2,cutValue_Xc)\n",
    "backgroundlike_logS2_afterCut = CutEvents(backgroundlike_logS2,cutValue_Xc)\n",
    "        \n",
    "_ = plt.hist(backgroundlike_logS2_afterCut, bins=backgroundlike_logS2Bins,fc=(0, 0, 1, 0.3),label=\"background-like events\")\n",
    "_ = plt.hist(signallike_logS2_afterCut, bins=backgroundlike_logS2Bins,fc=(1, 0, 0, 0.3),label=\"signal-like events\")\n",
    "_ = plt.xlabel(r'Log(S2 size)')\n",
    "_ = plt.ylabel(r'Counts per bin')\n",
    "_ = plt.yscale('log')\n",
    "_ = plt.legend()\n",
    "        \n",
    "print(\"Number of signal-like event remaining after cut: \", signallike_logS2_afterCut.size)\n",
    "print(\"Number of background-like events remaining after cut: \",backgroundlike_logS2_afterCut.size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba4e08f",
   "metadata": {},
   "source": [
    "# Questions for discussion\n",
    "2.1 Play around with the cut value, $X_c$, to get a sense of what events remain if you change $X_c$. Include in your write-up two screenshots of this plot, each corresponding to a different cut value. Include with both plots the number of signal-like and background-like events remaining for that cut value.\n",
    "\n",
    "2.2 In the end, we will want a cut that removes background events but keeps signal (dark matter) events. If we are expecting our dark matter events to follow a distribution with the same shape as the red histogram, where do you think we might want to set our cut value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f86f5e",
   "metadata": {},
   "source": [
    "# Acceptance, Leakage, and Optimizing our Cut\n",
    "\n",
    "The real \"art\" to performing a dark matter (or rare event) search is in figuring out the best place to put a background cut. To quantify this a bit, we have to define two quantities:\n",
    "\n",
    "<b>Signal-like event acceptance:</b> This is the fraction of signal-like events that remain once we cut away events above $X_{c}$. \n",
    "\n",
    "<b>Background-like event leakage:</b> This is the fraction of background-like events that remain once we cut away events above $X_{c}$.\n",
    "\n",
    "The goal, then, is to try to minimize the background leakage while keeping the signal acceptance high. Let's illustrate this with some calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ed760",
   "metadata": {},
   "source": [
    "3.1 In the code above, set $X_{c}$=2.0. How many true signal events do we accept with our cut? How many background events leak into our selection? What is the disadvantage of such a strict cut?\n",
    "\n",
    "3.2 In the code above, now set $X_{c}$=4.5. How many true signal events do we accept? How many background events leak into our selection? What is the disadvantage of such a relaxed cut?\n",
    "\n",
    "In principle, we'll want a cut somewhere in between $X_{c}$=2.0 and $X_{c}$=4.5, and we'll want that cut informed by the signal acceptance and background leakage. We compute those below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46dc5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nPoints = 100\n",
    "cutVal_list = np.linspace(2.0,4.5,nPoints)\n",
    "\n",
    "signalAcceptance = np.zeros(nPoints)\n",
    "backgroundLeakage = np.zeros(nPoints)\n",
    "counter = 0\n",
    "for cv in cutVal_list:\n",
    "    signalAcceptance[counter] = (CutEvents(signallike_logS2,cv).size)\n",
    "    backgroundLeakage[counter] = (CutEvents(backgroundlike_logS2,cv).size)\n",
    "    counter += 1\n",
    "\n",
    "signalAcceptance /= signallike_logS2.size\n",
    "backgroundLeakage /= backgroundlike_logS2.size\n",
    "\n",
    "\n",
    "_ = plt.plot(cutVal_list,signalAcceptance, label=r\"Signal Acceptance\")\n",
    "_ = plt.plot(cutVal_list,backgroundLeakage, label=r\"Background Leakage\")\n",
    "_ = plt.yscale('log')\n",
    "_ = plt.xlabel(r'Log(S2 size)')\n",
    "_ = plt.ylabel(r'Fraction of Events')\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f97416d",
   "metadata": {},
   "source": [
    "# Question for discussion\n",
    "\n",
    "4.1 Suppose we set our cut at $X_{c}$=3.5. Based on these curves, what is the fraction of background events that will survive the cut? What is the fraction of signal events that will survive the cut?\n",
    "\n",
    "Signal acceptance and background leakage curves are good tools to understand how to select cuts, because they describe how cuts affect the signal and background populations, independent of the normalizations those populations (i.e. how many signal/background events we have in total). However, these normalizations are important to consider in order to optimize our cut value.\n",
    "\n",
    "4.2 If my dark matter signal has the same distribution shape as the neutron calibration data, but we're only expecting 10 dark matter events total, on average how many dark matter events should survive a cut at $X_{c}$=3.5?\n",
    "\n",
    "4.3 If my background has the same distribution shape as the background calibration data, but we're expecting 200 background events total, on average how many background events should survive a cut at $X_{c}$=3.5?\n",
    "\n",
    "4.4 Assume a Poisson uncertainty in the surviving background events (i.e. the uncertainty is the square root of the number of surviving events). Given the number you found in 4.3, will a cut at $X_{c}$=3.5 allow us to confidently say that we've discovered dark matter in this scenario? Why or why not? Is there a way to better improve the sensitivity of our search?\n",
    "\n",
    "4.5 Using the answers to the last few questions, I want you to propose a cut value for $X_{c}$ that you think is best for confidently identifying whether we see dark matter events. Keep in mind that dark matter interactions are rare enough that none have been conclusively detected yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73b5946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
