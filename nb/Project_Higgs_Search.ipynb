{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4420be79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import scipy.optimize as optimize\n",
    "from functools import partial\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61de816d",
   "metadata": {},
   "source": [
    "# Searching for the Higgs boson\n",
    "\n",
    "### Introduction\n",
    "\n",
    "The overarching goal of this project is to search for the Higgs boson. The Higgs boson was discovered in July 2012 by two experiments, the ATLAS and CMS experiments. It was the last particle to be experimentally discovered in the Standard Model. The Standard Model is a theory describing how fundamental particles interact through the weak, electromagnetic, and strong forces. This figure from [Quanta magazine](https://www.quantamagazine.org/a-new-map-of-the-standard-model-of-particle-physics-20201022/) depicts the Standard Model particles:\n",
    "\n",
    "<img src=\"figures/StandardModel.png\" width=\"400\"/>\n",
    "\n",
    "\n",
    "To discover the Higgs boson, protons were collided at a center-of-mass energy of 7 and 8 TeV. When protons are collided at such a high energy, the protons \"break up\" into their constituent particles (called quarks and gluons). These constituent particles interact in a variety of ways according to the Standard Model and can produce other particles. The ATLAS and CMS experiments are huge detectors which measure these outgoing particles.\n",
    "\n",
    "Recall that in weeks 7 of this course we searched for dark matter in a simplified data set. In spirit this is similar to the dark matter search, but there are several key differences:\n",
    "\n",
    "1. **Detectors:** The detectors at CERN that were used to discover the Higgs particle are the size of a 6 story building (about 50 m long and 25 m tall).  The detectors surround the collision point, and are constructed to fully image the particles that are produced when two protons collide at very nearly the speed of light.  Sophisticated trigger and data analysis techniques are used to filter the data in order to find events that might have contained a Higgs boson.  \n",
    "2. **What to look for:** \n",
    "- The Higgs boson is unstable, and decays too quickly to other particles (the predicted lifetime is $\\approx10^{-22}$ seconds) to be directly \"imaged\". As such, physicists look for events with particles that are consistent with coming from the Higgs boson decay.  The Higgs can decay to a number of different particles, but we will be looking at decays to two photons. \n",
    "- In the dark matter search in Week 7, we used the **S2** variable (the size of the electron charge signal) to distinguish signal from background.  For the Higgs search we will instead be looking at the **mass** of the parent particle which decayed into two photons.  \n",
    "- For background events that mass will look like a falling distribution, and we will model it as a linear function.  For signal events that mass will be peaked distribution, centered at the mass of the Higgs particle ( $m_{H} = 125.1 \\frac{\\rm GeV}{c^2}$ ).   This means that in the Higgs search, we will be cutting on both sides of the signal. In other words, the signal events are $ | m - m_{H} | < w $, where $w$ is the width of the cut window.\n",
    "\n",
    "3. **Signal and background yield:** In this search, we have much more data, even at the last step of the data analysis.  Both the rate of signal events and background events are much higher than for the dark matter search.\n",
    "\n",
    "\n",
    "You can try two different ways of doing the search.\n",
    "\n",
    "1. **\"Cut and count\":**  \n",
    "- The general idea is to define what we call a signal region (or a region enriched in signal events), and a background region (a region enriched in background events), and to show that there are more events in the signal region that in the background region.\n",
    "- This would be straightforward if our background rate was constant as a function of mass. Then you can simply pick a window around where you expect a peak to be as the signal region, and another window far away from the peak, of the same width, as the background region. \n",
    "- In our case, since the background is not constant, you can consider picking two background regions, one on either side of the signal, and to average them. Or you can come up with a different way.\n",
    "\n",
    "<img src=\"figures/higgs_cut_and_count_2.png\" width=\"400\"/>\n",
    "\n",
    "\n",
    "2. **\"Fitting\":** \n",
    "- Pick a function to model your signal, and a separate one to model your background.\n",
    "- Fit your models to the data, and use the results to extract the size of the signal.\n",
    "\n",
    "<img src=\"figures/Higgs_Mass_fit.png\" width=\"400\"/>\n",
    "\n",
    "\n",
    "For comparison, here is a figure from the Higgs discovery paper from the ATLAS experiment:\n",
    "\n",
    "<img src=\"figures/2012Higgsplot.png\" width=\"400\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d764c90",
   "metadata": {},
   "source": [
    "### Potential goals for this project:\n",
    "\n",
    "1. Optimize the width of the cut window for the best significance for discovering the Higgs boson. To do this, define a metric that quantifies your expected significance given the expected numbers of signal and background events, and explain why you chose this metric.\n",
    "\n",
    "2. Apply the \"cut and count\" analysis to the real data and calculate the significance. \n",
    "\n",
    "3. Plot the increase in significance, that you expect as a function of time using the \"cut and count\" analysis. In other words, how would your ability to discover the Higgs scale with more data? Come up with a formula that describes the increase vs time. \n",
    "\n",
    "4. Apply the \"fitting\" analysis to the real data and come up with a way to quantify the significance of the results.\n",
    "\n",
    "5. Compare the results of the \"fitting\" analysis with the \"cut and count\" analysis. \n",
    "\n",
    "Try to complete all of these goals (or similar goals if you have your own ideas). We have written much of the code for you, so be sure to explain each plot and number that you make thoroughly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6020d5a8",
   "metadata": {},
   "source": [
    "# Project details\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855cb5c5",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "This is **24 months** of simulated data.\n",
    "\n",
    "We have histogrammed the Higgs mass data in units of $1~{\\rm GeV}/{c^2}$, as was done in the plots above. We will look at all the data between $90$ and $160~{\\rm GeV}/{c^2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc66963",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt('../data/Higgs.txt')\n",
    "mass_grid = np.linspace(90., 160., 71) # for reference\n",
    "masses = data[:,0]\n",
    "nevts = data[:,1]\n",
    "errors = np.sqrt(nevts)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "ax.errorbar(masses, nevts, yerr=errors, fmt='.')\n",
    "\n",
    "ax.set_xlabel(r\"Mass [GeV/$c^2$]\")\n",
    "ax.set_ylabel(r\"Counts [per GeV/$c^2$]\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35a1e1e",
   "metadata": {},
   "source": [
    "## Useful variables\n",
    "\n",
    "First, let's make our lives easy by defining some variables based on the measured Higgs particle mass, making an intial guess for the mass itself, and a initial guess for the width of the mass peak. **Define these variables based on the plots above.**\n",
    "\n",
    "(N.B. If you look up the theoretical width of the Higgs peak due to quantum-mechanical effects, it's about $4~{\\rm MeV}/{c^2}$, which is much narrower than the width we see. The width of the peak is entirely dominated by detector effects.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4627b637",
   "metadata": {},
   "outputs": [],
   "source": [
    "Higgs_Mass  = None # In Units of GeV / c**2\n",
    "Higgs_Width = None # In Units of GeV / c**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0485e2c2",
   "metadata": {},
   "source": [
    "## Signal and background models\n",
    "\n",
    "Here are some initial models that you can use. You may want to optimize these models. Note that the models are expressed in units of events per GeV per month.\n",
    "\n",
    "`Gauss`: tells you the value from a gaussian\n",
    "* Function arguments\n",
    "    * x: x-value(s) to evaluate at \n",
    "    * nsig: normalization factor of gaussian\n",
    "    * mu: center\n",
    "    * sigma: width\n",
    "\n",
    "`poly1`: tells you the value of a linear function\n",
    "* Function arguments\n",
    "    * x: x-value(s) to evaluate at \n",
    "    * ref_mass: x offset\n",
    "    * offset: y offset\n",
    "    * slope: slope of function\n",
    "    \n",
    "`passed_cuts`: tells you how many signal and background events from the idealized data pass your cuts if you use a cut window of a particular width, using models for how much signal and background we expect.\n",
    "* Function arguments\n",
    "    * cut_width: half of the width of your signal/background region \n",
    "    * masses: the array of mass points in data\n",
    "    * model_sig: the values of your signal model\n",
    "    * model_bkg: the values of your background model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1d8738",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Gauss(x, nsig, mu, sigma):\n",
    "    return nsig*stats.norm(loc=mu, scale=sigma).pdf(x)\n",
    "\n",
    "def poly1(x, ref_mass, offset, slope):\n",
    "    return offset + (x-ref_mass)*slope\n",
    "\n",
    "def passed_cuts(cut_width, masses, model_sig, model_bkg, Higgs_Mass):\n",
    "    mask = np.abs(masses - Higgs_Mass) < cut_width\n",
    "    n_sig = np.sum(model_sig[mask])\n",
    "    n_bkg = np.sum(model_bkg[mask])\n",
    "    return n_sig, n_bkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bdc8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_mass                    = Higgs_Mass\n",
    "nsig_per_month              = 20.\n",
    "nbkg_per_gev_per_month      = 40.\n",
    "bkg_slope_per_gev_per_month = -0.2\n",
    "model_bkg = poly1(mass_grid, ref_mass, nbkg_per_gev_per_month, bkg_slope_per_gev_per_month)\n",
    "model_sig = Gauss(mass_grid, nsig_per_month, Higgs_Mass, Higgs_Width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6d42fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "ax.scatter(mass_grid, model_sig, label=\"Signal\", marker='.')\n",
    "ax.scatter(mass_grid, model_bkg, label=\"Background\", marker='.')\n",
    "ax.scatter(mass_grid, model_sig+model_bkg, label=\"Combined\", marker='.')\n",
    "\n",
    "ax.set_xlabel(r\"Mass [GeV/$c^2$]\")\n",
    "ax.set_ylabel(r\"Counts [per GeV/$c^2$ / month]\")\n",
    "\n",
    "ax.legend(fontsize=10)\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1b508d",
   "metadata": {},
   "source": [
    "## Useful functions to optimize cuts and set expectations\n",
    "\n",
    "You can use these three functions to:\n",
    "\n",
    "1. `plot_nexp_passed_cuts`: makes a plot of how many signal and background events from your model data pass your cuts if you as a function of the cut width.\n",
    "* Function arguments:\n",
    "    * masses: the array of mass points in data\n",
    "    * model_sig: the values of your signal model\n",
    "    * model_bkg: the values of your background model\n",
    "\n",
    "2. `find_sig2noise`: makes of plot of the significance of the signal.\n",
    "* Function arguments:\n",
    "    * masses: the array of mass points in data\n",
    "    * model_sig: the values of your signal model\n",
    "    * model_bkg: the values of your background model\n",
    "\n",
    "3. `sig2noise_v_time`: shows you how the significance will increase with time, assuming you keep taking data.\n",
    "* Function arguments:\n",
    "    * masses: the array of mass points in data\n",
    "    * model_sig: the values of your signal model\n",
    "    * model_bkg: the values of your background model\n",
    "    \n",
    "** Note that you will have to define your own `significance` function. This should depend on the expected number of background events and the number of signal events and should represent your confidence in discovering dark matter if it exists. Hint: Think in terms of sigmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f80e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def significance(nsig, nbkg):\n",
    "    significance = None # Define your significance function here\n",
    "    return significance\n",
    "\n",
    "def plot_nexp_passed_cuts(masses, model_sig, model_bkg, show=False):\n",
    "    sig_cts = np.zeros(26)\n",
    "    bkg_cts = np.zeros(26)\n",
    "    widths = np.linspace(0, 25, 26)\n",
    "    for i, width in enumerate(widths):\n",
    "        sig_cts[i], bkg_cts[i] = passed_cuts(width, masses, model_sig, model_bkg, Higgs_Mass)\n",
    "        \n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    ax.plot(widths, sig_cts, label=\"Signal\")\n",
    "    ax.plot(widths, bkg_cts, label=\"Background\")\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel(r\"Cut Width [GeV / $c^2$]\")\n",
    "    ax.set_ylabel(r\"Events [per GeV / $c^2$ / month]\")\n",
    "    ax.legend(fontsize=10)\n",
    "    fig.tight_layout()\n",
    "    if show:\n",
    "        plt.show()\n",
    "    \n",
    "def find_sig2noise(masses, model_sig, model_bkg, plot=True):\n",
    "    sig_cts = np.zeros(26)\n",
    "    bkg_cts = np.zeros(26)\n",
    "    widths = np.linspace(0, 25, 26)\n",
    "    for i, width in enumerate(widths):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        sig_cts[i], bkg_cts[i] = passed_cuts(width, masses, model_sig, model_bkg, Higgs_Mass)\n",
    "    sig2noise = np.zeros(26)\n",
    "    sig2noise[1:] = significance(sig_cts[1:],bkg_cts[1:])\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        ax.plot(widths, sig2noise)\n",
    "        ax.set_xlabel(r\"Cut Width [GeV / $c^2$]\")\n",
    "        ax.set_ylabel(r\"Significance for one month\")\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "    return sig2noise\n",
    "\n",
    "def sig2noise_v_time(mass_grid, model_sig, model_bkg, plot=True):\n",
    "    max_s2n = np.zeros(24)\n",
    "    best_cut = np.zeros(24)\n",
    "    n_months_array = np.arange(24)\n",
    "    for n_months in n_months_array:\n",
    "        if n_months == 0:\n",
    "            continue\n",
    "        s2n = find_sig2noise(mass_grid, n_months*model_sig, n_months*model_bkg, plot=False)\n",
    "        max_s2n[n_months] = np.max(s2n)\n",
    "        best_cut[n_months] = np.argmax(s2n)\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        ax.scatter(n_months_array, max_s2n)\n",
    "        ax.set_xlabel(r\"Time [months]\")\n",
    "        ax.set_ylabel(r\"Significance for N months\")\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return max_s2n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7349a3e",
   "metadata": {},
   "source": [
    "## Useful functions for the cut and count analysis\n",
    "\n",
    "You can use these two functions to:\n",
    "\n",
    "`extract_sig_from_data`: tells you many events are in your signal region on the \"real\" data.  Since it is real data, you don't know if they are signal or background.\n",
    "\n",
    "* Function arguments:\n",
    "    * cut_width: half of the width of your signal/background region \n",
    "    * masses: the array of mass points in data\n",
    "    * nevs: the number of events observed a each mass in data   \n",
    "    * Higgs_mass: the center of your signal region\n",
    "\n",
    "\n",
    "`extract_bkg_from_data`: tells you many events are in your background region on the \"real\" data and the Poisson error.\n",
    "\n",
    "* Function arguments:\n",
    "    * cut_width: half of the width of your signal/background region \n",
    "    * masses: the array of mass points in data\n",
    "    * nevs: the number of events observed a each mass in data\n",
    "    * low_center: the center of your \"lower\" background region \n",
    "    * high_center: the center of your \"higher\" background region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd03b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sig_from_data(cut_width, masses, nevts, Higgs_Mass):\n",
    "    mask = np.abs(masses - Higgs_Mass) < cut_width\n",
    "    return np.sum(nevts[mask])\n",
    "\n",
    "def estimate_bkg_from_data(cut_width, masses, nevts, low_center, high_center):\n",
    "    mask_bkg_lo = np.abs(masses-low_center) < cut_width\n",
    "    mask_bkg_hi = np.abs(masses-high_center) < cut_width\n",
    "    mask_bkg = np.bitwise_or(mask_bkg_lo, mask_bkg_hi)\n",
    "    bkg_estimate = 0.5 * np.sum(nevts[mask_bkg])\n",
    "    return (bkg_estimate, np.sqrt(bkg_estimate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1ecab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to use estimate_bkg_from_data\n",
    "bkg_yld, bkg_err = estimate_bkg_from_data(10, masses, nevts, 105, 145)\n",
    "print(f\"In background region, I found {bkg_yld} +/- {bkg_err} events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c79d33",
   "metadata": {},
   "source": [
    "## Useful functions for fitting the data\n",
    "\n",
    "The important one here is `fitAndPlotResult`, which will find take your data, fit your model, and plot the results. It returns the fitted number of signal events and the error on that fit.\n",
    "\n",
    "* Function arguments:\n",
    "    * masses: the array of mass points\n",
    "    * nevs: the number of events observed a each mass\n",
    "    * ref_mass: the reference mass for the background model\n",
    "    * init_pars: guesses for the initial parameters of the model. Should be in the format of a list: [p0,p1,p2,p3]\n",
    "\n",
    "The three model parameters that are fitted for are: \n",
    "\n",
    "1. The total number of signal events.\n",
    "2. The number of background events in the bin at the reference mass.\n",
    "3. The slope of the background model, in events per bin.\n",
    "4. The width of the signal peak.\n",
    "\n",
    "The other parameters will be fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b79b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_func(x, ref_mass, nsig, offset, slope, width):\n",
    "    return Gauss(x, nsig, Higgs_Mass, width) + poly1(x, ref_mass, offset, slope)\n",
    "\n",
    "def generic_chi2(params, data_vals, model, x, ref_mass):\n",
    "    model_vals = model(x, ref_mass, *params)\n",
    "    return np.sum(((data_vals - model_vals)**2)/data_vals)\n",
    "\n",
    "def cost_func(data_vals, model, x, ref_mass):\n",
    "    return partial(generic_chi2, data_vals=data_vals, model=model, x=x, ref_mass=ref_mass)\n",
    "\n",
    "def fitAndPlotResult(masses, nevts, ref_mass, init_pars):\n",
    "    our_cost_func = cost_func(nevts, model_func, masses, ref_mass=ref_mass)\n",
    "    result = optimize.minimize(our_cost_func, x0=np.array(init_pars))\n",
    "    fit_pars = result['x']\n",
    "    cov = result['hess_inv']\n",
    "    model_fit = model_func(masses, ref_mass, *fit_pars)\n",
    "    background_fit = poly1(masses, ref_mass, fit_pars[1], fit_pars[2])\n",
    "\n",
    "    print(\"Best Fit ---------\")\n",
    "    print(f\"Normalization factor for gaussian : {fit_pars[0]:0.1f} [Events]\")\n",
    "    print(f\"        Fitted width for gaussian : {fit_pars[3]:0.4f} GeV/c^2\")\n",
    "    print(f\"      Linear offset at Higgs mass : {fit_pars[1]:0.2f} [Events / GeV/c^2]\")\n",
    "    print(f\"                     Linear slope : {fit_pars[2]:0.2f} [Events / GeV/c^2 / GeV/c^2]\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    ax.errorbar(masses, nevts, yerr=np.sqrt(nevts), fmt='.', label=\"data\")\n",
    "    ax.plot(masses, background_fit, label=\"background model\")\n",
    "    ax.plot(masses, model_fit, label=\"full model\")\n",
    "    ax.set_xlabel(r\"mass $[\\frac{\\rm GeV}{c^2}]$\")\n",
    "    ax.set_ylabel(r\"Events $[{\\rm per }\\frac{\\rm GeV}{c^2}]$\")\n",
    "    ax.legend(fontsize=10)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return (fit_pars[0], np.sqrt(cov[0,0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
