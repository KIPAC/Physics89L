{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89768d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as sps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de77295",
   "metadata": {},
   "source": [
    "# Project: Exploring the Hubble \"Tension\"\n",
    "\n",
    "Recall that in weeks 1 and 2 of this course we explored some measurements of the Hubble constant. We used them to study some simple statistics and make an inverse variance weighted average of measurements that took into account the fact that some of the measurements had smaller uncertainties than others.\n",
    "\n",
    "It turns out that the inconsistency in the measurements of the Hubble constant is actually one of the biggest open questions in cosmology.  Roughly speaking, measurements of the Hubble constant can be divided into two types. \n",
    "\n",
    "1. \"Early time\" measurements that use our knowledge of cosmology and look at structures in the very early universe, e.g., the primoridal background of light left over from the Big Bang that is now visible to us as a bath of faint microwave radiation, to determine the Hubble parameter.  These measurements are more sensitive to our understanding of cosmology.\n",
    "\n",
    "2. \"Late time\" measurements that build on the so-called distance ladder to estimate the distance to supernovae and compare that to the redshift of their spectral lines (i.e., the sort of measurement we did in week 6 looking at the spectrum of a Galaxy using SDSS data).  These measurements are more sensitive to our ability to build up a distance ladder out to billions of light years away.\n",
    "\n",
    "We've provided you with a new data file, which is a sub-set of the more recent Hubble data measurements, including an extra column telling you if a particular measurement is type 1 or type 2.\n",
    "\n",
    "We expect you to complete all of the following goals for full credit. If you prefer to replace on of these goals with your own goal, please consult the instructor/TA.\n",
    "\n",
    "1. Come up with a way to evaluate the consistency of all of the data before subdividing into \"Early Time\" and \"Late Time\" measurements. Make sure you take the errors into account, quote a p-value (probability estimate), and explain why your results indicate the data should be subdivided. \n",
    "\n",
    "2. Make a nice plot (or two) that summarizes the difference between \"Early Time\" results and \"Late Time\" results.\n",
    "\n",
    "3. Come up with a way to evaluate the consistency of the data within each subset (\"Early Time\" and \"Late Time\"). Make sure you take the errors into account, quote a p-value (probability estimate), and interpret your result.\n",
    "\n",
    "4. Come up with a way to evaluate the consistency of the two different subsets (\"Early Time\" and \"Late Time\") with each other. Make sure you take the errors into account, quote a p-value (probability estimate), and interpret your result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99e5945",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(open(\"../data/Hubble_extra.txt\", 'rb'), usecols=[1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83129e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how we pull out the data from columns in the array.\n",
    "H0_measured = data[:,0]\n",
    "H0_errorLow = data[:,1]\n",
    "H0_errorHigh = data[:,2]\n",
    "H0_type = data[:,3]\n",
    "N_measurements = H0_measured.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87df7eff",
   "metadata": {},
   "source": [
    "# Useful functions\n",
    "\n",
    "The first one returns useful statistical quantities, given arrays of values and associated error estimates.\n",
    "\n",
    "The second one takes a set of Hubble parameter measurements and their associated error bars (both low and high side) and uses the first function to print out the statistical quantities, then makes a plot of the measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991cc45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStats(values, errors):\n",
    "    nvals = np.size(values)\n",
    "    mean = np.mean(values)\n",
    "    std = np.std(values)\n",
    "    err = std / np.sqrt(nvals)\n",
    "    wts = 1/(errors*errors)\n",
    "    wmean = np.sum(values*wts)/np.sum(wts)\n",
    "    werr = np.sqrt(1/np.sum(wts))\n",
    "    return (nvals, mean, std, err, wmean, werr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678fe8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStatsAndPlotValues(values, errs_lo, errs_hi):\n",
    "    errs = 0.5*(errs_lo + errs_hi)\n",
    "    stats = getStats(values, errs)\n",
    "    print(\"Statistics for these data ----\")\n",
    "    print(\"N                      : %i\" % stats[0])\n",
    "    print(\"Mean                   : %0.2f\" % stats[1])\n",
    "    print(\"Standard Deviation     : %0.2f\" % stats[2])\n",
    "    print(\"Standard Error         : %0.2f\" % stats[3])\n",
    "    print(\"Weighted Mean          : %0.2f\" % stats[4])\n",
    "    print(\"Error on Weighted Mean : %0.2f\" % stats[5])\n",
    "    _ = plt.errorbar(values, np.arange(stats[0]), xerr=(errs_lo, errs_hi), fmt=\".\", color='k')\n",
    "    _ = plt.xlabel(\"Hubble Constant [km/s/Mpc]\")\n",
    "    _ = plt.ylabel(\"Experiment number\")\n",
    "    _ = plt.errorbar(stats[1], stats[0]/2., xerr=stats[3], yerr=stats[0]/2, fmt='o', color='b', label=\"Mean\")\n",
    "    _ = plt.errorbar(stats[4], stats[0]/2., xerr=stats[5], yerr=stats[0]/2, fmt='o', color=\"r\", label=\"Weighted Mean\")\n",
    "    _ = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a700004d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "getStatsAndPlotValues(H0_measured, H0_errorLow, H0_errorHigh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd3e172",
   "metadata": {},
   "source": [
    "# Masking data by measurement type\n",
    "\n",
    "This next cell shows how to select measurements of either type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca18594",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_1_mask = H0_type == 1\n",
    "type_2_mask = H0_type == 2\n",
    "print(\"Early time measurements\", H0_measured[type_1_mask])\n",
    "print(\"Late time measurements\", H0_measured[type_2_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8599bc",
   "metadata": {},
   "source": [
    "# Going from significance in sigma to p-value and vice versa\n",
    "\n",
    "These functions might be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5113d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_value = 3\n",
    "p_value = sps.norm().sf(sigma_value)\n",
    "sigma_check = sps.norm().isf(p_value)\n",
    "print(\"Original sigma : %.2f\" % sigma_value)\n",
    "print(\"P-value        : %.2e\" % p_value)\n",
    "print(\"Back to sigma  : %.2f\" % sigma_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d06087",
   "metadata": {},
   "source": [
    "# Going from a chi-squared to a p-value\n",
    "\n",
    "This function tells you the p-value of observing a given total chi squared value given df = n-1 measurements.\n",
    "\n",
    "Where df is the \"degrees of freedom,\" so if we have, say, 11 measurements but are picking one value for the Hubble constant to try and match all the data, that leaves us with 10 \"degrees of freedom\".\n",
    "\n",
    "I.e., if we had 11 measurements, and the total chi squared summed up to 11.5, then the p-value would be about 0.32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf31e8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The p-value for chi squared = 11.5 with 10 degrees of freedom is %0.2f\" % sps.chi2(df=10).sf(11.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
