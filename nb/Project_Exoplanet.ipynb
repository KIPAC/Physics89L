{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93fb63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import scipy.optimize as optimize\n",
    "from scipy.fft import fft, fftfreq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "865a067a",
   "metadata": {},
   "source": [
    "# Searching for Exoplanets\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Recall that in week 8 of this course, we explored analyzing data in the frequency domain using Fourier transforms. In this project, you will further explore this concept by applying some of the basic statistical techniques that we covered at the beginning of the course, but now in the frequency domain. Fourier analysis has many applications in physics and astronomy, and in this project, you will investigate its use in the search for exoplanets.\n",
    "\n",
    "There are now many methods for detecting exoplanets, but the first exoplanet discoveries in the late 1980s and early '90s were made using the *radial velocity method*. This technique is based on the fact that the gravitational force from an exoplanet will have a small, but measurable, effect on the motion of the host star. Recall that in a planetary system, both the planet and the star will orbit around the center of mass of the system. Even though the star will typically have much more mass that the planet, the center of mass of the combined system will not be exactly at the center of mass of the star. This will cause the star to \"wobble\".\n",
    "\n",
    "Due to the Doppler effect, this slight wobble will cause small shifts in the spectrum of the host star over time. These radial velocities can be very small -- the first exoplanets discovered had velocities of just a few m/s -- so measurements of the spectrum must be extremely precise. This measurement technique is summarized in the image below.\n",
    "\n",
    "<img src=\"figures/Radial-Velocity-Method-star-orbits.png\" width=600>\n",
    "\n",
    "The key to detecting these extremely small shifts and distinguishing them from background fluctuations is that they will be periodic. This is why Fourier analysis is such a powerful technique for analyzing this type of data. When we look at the data in the time domain, it may not be possible to pick out the periodic signal from the background. When we convert to the frequency domain, however, a small periodic signal can become quite obvious.\n",
    "\n",
    "In this project, you will consider some effects that can make it easier or harder to detect a periodic signal.\n",
    "\n",
    "1. The quality of the measurements. We will study this effect by adding noise to the measurements of radial velocity, thus degrading the signal.\n",
    "\n",
    "2. The number of measurements over time. If we take more measurements over a longer time range, it will be easier to distinguish the periodic signal from background.\n",
    "\n",
    "We have provided a data sample to use in your investigation. This is idealized data, based on radial velocity measurements taken from [51 Pegasi](https://en.wikipedia.org/wiki/51_Pegasi) in 1995, which led to the first discovery of an exoplanet orbiting a Sun-like star. \n",
    "\n",
    "## Potential goals for this project:\n",
    "\n",
    "1. Run through the four cases in this notebook that demonstrate the effects of adding noise and reducing the observation time.\n",
    "\n",
    "2. Decide how to characterize the statistical significance of the peak in the Fourier transform, and whether it constitutes a discovery.\n",
    "\n",
    "3. Explore how the statistical significance changes as we degrade the data, and discuss your findings using both text and plots.\n",
    "\n",
    "4. Imagine you are conducting an exoplanet search using a detector with a known level of noise. Estimate the minimum observation time you need to make a discovery with a high degree of confidence (i.e. at least 5$\\sigma$)?\n",
    "\n",
    "These four goals are suggestions, and you should feel free to substitute your own ideas, as long as your overall project has a similar level of complexity to the listed goals. We have provided a few functions and code templates that you will probably find useful, and you are encouraged to use these as starting points for writing your own code. Four scenarios are briefly discussed to illustrate some of the effects of degradation on the data to get you started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6745b5fb",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1caef2c2",
   "metadata": {},
   "source": [
    "### Plot the radial velocity as a function of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ed3c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rvel(date, rvel):\n",
    "    plt.scatter(date, rvel)\n",
    "    plt.xlabel(r'Observation Time [days]')\n",
    "    plt.ylabel(r'$\\Delta v_{\\rm rad} [\\frac{m}{s}]$')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c9182f7",
   "metadata": {},
   "source": [
    "### Degrade data by adding noise and/or reducing number of observations\n",
    "\n",
    "This function allows you to:\n",
    "- Add random noise to the radial velocity signal, drawn from a Gaussian distribution with $\\sigma = $ `noise_scale`\n",
    "- Reduce the time range of the measurements by a factor of `tfrac`, where $ 0 \\leq $ `tfrac` $ \\leq 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f067d5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "\n",
    "def degrade_data(date, rvel, noise_scale=0.01, tfrac=1.):\n",
    "    tmax = tfrac*np.max(date)\n",
    "    mask = date < tmax\n",
    "    return (date[mask], rvel[mask] + rng.normal(loc=0, scale=noise_scale, size=mask.sum()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9d98c40",
   "metadata": {},
   "source": [
    "### Take the Fourier transform of a time series\n",
    "\n",
    "This FFT (fast Fourier transform) function returns `xf, yf` where `xf` and `yf` are the frequency and amplitude of the transformed data, respectively. `xf` has units of days $^{-1}$ and `yf` is in arbitrary units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e880b244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_fft(date, rvel, plot=True):\n",
    "    # Number of sample points\n",
    "    N = len(date)\n",
    "\n",
    "    # Arbitrary offset in data\n",
    "    offset = np.mean(rvel)\n",
    "\n",
    "    # sample spacing\n",
    "    T = np.mean(date[1:] - date[0:-1])\n",
    "\n",
    "    yf = fft(rvel-offset)\n",
    "    xf = fftfreq(N, T)[:N//2]\n",
    "\n",
    "    if plot:\n",
    "        plt.plot(xf, 2.0/N * np.abs(yf[0:N//2]))    \n",
    "        plt.ylabel(\"Signal [arbitrary units]\")\n",
    "        plt.xlabel(r\"Frequency [${\\rm days}^{-1}$]\")\n",
    "\n",
    "        freq_max = xf[np.argmax(np.abs(yf[0:N//2]))]\n",
    "        period = 1./freq_max\n",
    "        annotation = (f\"f ~ {freq_max:0.2f} days^-1\\n\"\n",
    "                      f\"P ~ {period:0.2f} days\"\n",
    "                     )\n",
    "        plt.annotate(annotation, (0.6, 0.8), xycoords=\"figure fraction\")\n",
    "        \n",
    "    return xf, 2.0/N * np.abs(yf[0:N//2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6079b09",
   "metadata": {},
   "source": [
    "### Characterize the peak and noise level in the FFT\n",
    "\n",
    "This function returns a dictionary containing statistical information about the transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1b8761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_noise_stats(xf, yf, verbose=False):\n",
    "    result = {}\n",
    "    result[\"peak_height\"] = np.max(yf)\n",
    "    result[\"peak_freq\"] = xf[np.argmax(yf)]\n",
    "    min_bin = np.searchsorted(xf, 0.5)\n",
    "    other_data = yf[min_bin:]\n",
    "    result[\"mean\"] = np.mean(other_data)\n",
    "    result[\"std\"] = np.std(other_data)\n",
    "    if verbose:\n",
    "        print(\"The peak height is {peak_height:.2f} at frequency {peak_freq:.2f} day^-1\".format(**result))\n",
    "        print(\"Away from the peak, the mean amplitude is {mean:.2f} and the standard deviation is {std:.2f}\".format(**result))\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38ebe9ae",
   "metadata": {},
   "source": [
    "## Data taking scenarios\n",
    "\n",
    "The following scenarios are provided to illustrate how the data changes in both the time and frequency domains, for various values of noise level and observation time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e189a6a1",
   "metadata": {},
   "source": [
    "### 1. Idealized data (no noise)\n",
    "\n",
    "This case represents some very idealized measurements. There is no instrumental error, and we observe the star a few times a day for 40 days. The result is a very clear and convincing periodic signal, visible in both the time and frequency domain plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46028e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(open(\"../data/51peg_model_rvs.txt\", 'rb'), usecols=range(2))\n",
    "\n",
    "# This is how we pull out the data from columns in the array.\n",
    "date = data[:,0] - np.min(data[:,0])\n",
    "rvel = data[:,1]\n",
    "\n",
    "plot_rvel(date, rvel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f61a024",
   "metadata": {},
   "outputs": [],
   "source": [
    "xf, yf = do_fft(date, rvel)\n",
    "fft_noise_stats(xf, yf, True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4748692f",
   "metadata": {},
   "source": [
    "### 2. Shorter observation, no noise\n",
    "\n",
    "In this case we still have no measurment error, but we only have 20 days of observation data instead of 40.  We still get a very clear signal in both plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc38876",
   "metadata": {},
   "outputs": [],
   "source": [
    "less_data = degrade_data(date, rvel, tfrac=0.5)\n",
    "plot_rvel(less_data[0], less_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc75e5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xf, yf = do_fft(less_data[0], less_data[1])\n",
    "fft_noise_stats(xf, yf, True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dde73862",
   "metadata": {},
   "source": [
    "### 3. Full observation time, with noise added\n",
    "\n",
    "In this case we have added about $50$ m/s of noise in the measurements of $v_\\mathrm{rad}$. Even though we can't really see a periodic signal in the time domain, the signal is very clear in the Fourier transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a79eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_data = degrade_data(date, rvel, noise_scale=100.)\n",
    "plot_rvel(noisy_data[0], noisy_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8728575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xf, yf = do_fft(noisy_data[0], noisy_data[1])\n",
    "fft_noise_stats(xf, yf, True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b45eef6c",
   "metadata": {},
   "source": [
    "### 4. Shorter observation, with noise added\n",
    "\n",
    "In this case we have both a shorter observation time and noisy data, and there is no longer a visible signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3b8f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_short_data = degrade_data(date, rvel, noise_scale=100., tfrac=0.5)\n",
    "plot_rvel(noisy_short_data[0], noisy_short_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9240e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xf, yf = do_fft(noisy_short_data[0], noisy_short_data[1])\n",
    "fft_noise_stats(xf, yf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e280d8cb",
   "metadata": {},
   "source": [
    "## Code templates\n",
    "\n",
    "The following templates are provided for you to fill in with code and use in your analysis. You can use these, as well as the functions above, as examples to guide you in writing your own analysis code."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77aef9a8",
   "metadata": {},
   "source": [
    "### Calculate statistical significance for a given combination of noise and observation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a01c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_significance(noise, tfrac):\n",
    "    noisy_data = degrade_data(date, rvel, noise, tfrac)\n",
    "    xf, yf = do_fft(noisy_data[0], noisy_data[1], plot=False)\n",
    "    fft_stats = fft_noise_stats(xf, yf)\n",
    "    \n",
    "    ## your code here -- calculate and return the significance ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd6cdb91",
   "metadata": {},
   "source": [
    "### Plot significance as a function of both noise level and observation time\n",
    "\n",
    "The below template illustrates one way of visualizing the data that may be helpful. You may also want to write code to make some one dimensional plots, using `plt.plot(x, y)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f75b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use np.linspace to get an evenly spaced vector of values \n",
    "## Replace the values in the arguments below with start, stop, and number of steps\n",
    "noises = np.linspace(0., 0., 0)\n",
    "\n",
    "## Your t_fracs should be at least 0.025, otherwise you will have zero data points in your\n",
    "## time series, which will cause an error. Feel free to experiment with the bounds as long\n",
    "## as 0.025 <= t_frac <= 1.0\n",
    "t_fracs = np.linspace(0.025, 1.0, 0)\n",
    "\n",
    "tt, nn = np.meshgrid(noises, t_fracs) # converts the above vectors to grids\n",
    "\n",
    "## this converts your significance function so that it can be used on numpy arrays\n",
    "v_get_significance = np.vectorize(get_significance)\n",
    "sig_2d = v_get_significance(tt, nn)\n",
    "\n",
    "## Make the 2D plot. Comment or remove \"norm=colors.LogNorm()\" to switch between\n",
    "## linear and logarithmic scale\n",
    "plt.imshow(sig_2d, extent=(noises[0], noises[-1], t_fracs[0], t_fracs[-1]), aspect=\"auto\", \n",
    "           origin=\"lower\", norm=colors.LogNorm())\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Noise [m/s]\")\n",
    "plt.ylabel(\"Time fraction\")\n",
    "\n",
    "## Uncomment the line below to draw contour(s) over the plot\n",
    "## Change `levels` below to your list of contour levels\n",
    "#plt.contour(noises, times, sig_2d, levels=[0.], colors=[\"red\"], origin=\"lower\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
