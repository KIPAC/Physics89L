{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency analysis.\n",
    "\n",
    "### Goals:\n",
    "\n",
    "1. To gain an intuitive understanding of frequency analysis, by applying frequency analysis to some audio clips.\n",
    "2. To deepen that understanding by applying frequency-based filters and by applying frequency analysis to simplified waveforms.\n",
    "\n",
    "### Timing\n",
    "\n",
    "1. Try to finish this notebook in 30-35 minutes.\n",
    "\n",
    "### Question and Answer Template\n",
    "\n",
    "You can go to the link below, and do \"file\" -> \"make a copy\" to make yourself a google doc that you can use to fill in the answers to the question in this weeks notebooks.\n",
    "\n",
    "https://docs.google.com/document/d/1va2FBr_smgAQoA3sfFUr-7YVUBoQgQdOOOrBtR7fD_M/edit?usp=drive_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.signal import square\n",
    "\n",
    "## Import some methods specific for .wav files\n",
    "from scipy.io.wavfile import read, write\n",
    "\n",
    "## Import some methods for audio playback and image display\n",
    "from IPython.display import Audio, Image\n",
    "\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on the functions used in this week's notebooks.\n",
    "\n",
    "This week we are going to be using a number of advanced functions for signal processing. Rather than try to explain the functions in great detail, we think it is more useful to focus on the figures and the associated explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Time Series Data \n",
    "\n",
    "In a physical experiment, oftentimes the data we are collecting is acquired over time. One simple way to visualize such a dataset is to just plot each data point as a function of time, which is exactly what we did in weeks 4 and 5 with the Vela Pulsar data that the Fermi Gamma-ray Space Telescope has been collecting for 13 years. We saw that this representation of the data was useful for quantifying the correlation between gamma-ray fluctuations and time, and we even fit a model that described how the data changed as time went on. \n",
    "\n",
    "In this next set of notebooks, we are going to explore a complementary visualization of the data that decomposes a time-based dataset, or time series signal, into the various frequency components that make up the signal. Although this might sound confusing and abstract at first, one intuitive way to understand this concept is by applying these techniques to music!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will begin by downloading various audio files that we have provided for you. Please select one music file (whichever one you want, the choice is not important for the rest of the lab) and play it to make sure you can hear the music."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## UN-COMMENT ONE OF THE AUDIO FILES BELOW BY REMOVING THE # SYMBOL\n",
    "\n",
    "# wav = os.path.join('audio_files','ImperialMarch60.wav')\n",
    "# wav = os.path.join('audio_files','Fanfare60.wav')\n",
    "wav = os.path.join('audio_files','CantinaBand60.wav')\n",
    "# wav = os.path.join('audio_files','PinkPanther60.wav')\n",
    "\n",
    "## Read the audio file and extract the sample rate and number samples\n",
    "fsamp, samps = read(wav)\n",
    "Audio(samps, rate=fsamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have listened to the music, we will visualize the audio as a function of time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_samples = len(samps)\n",
    "time_seconds = total_samples / fsamp\n",
    "\n",
    "## Define some plotting limits for the time-axis. Default value shows\n",
    "## the entire file, but YOU CAN CHANGE THEM to zoom in on certain\n",
    "## sections of the file\n",
    "xlim = (0, time_seconds)\n",
    "\n",
    "## Creat a time-vector for plotting, based on the extracted sample\n",
    "## rate and the number of samples\n",
    "time_vector = np.linspace(0, time_seconds, total_samples)\n",
    "\n",
    "## Plot the audio file in the time domain.\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "ax.plot(time_vector, samps)\n",
    "ax.set_title(\"Audio file in the time domain\")\n",
    "\n",
    "ax.set_xlabel('Time (seconds)')\n",
    "ax.set_ylabel('Amplitude (arb. units)')\n",
    "\n",
    "ax.set_xlim(*xlim)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this representation, the amplitude of the audio signal relates to the volume of the sound being heard. Sound is fundamentally made up of acoustic waves that create vibrations in a medium, and in a sound recording device (a microphone) these vibrations are collected and transformed into equivalent electronic waves that can be processed, edited, and eventually converted back into audio through a speaker system. Because of the natural interpretation of sound as being made up of waves, it makes sense for us to represent the audio in terms of the frequency components that make up the sound, which you can see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSpectrum(y, fsamp, xlog=True, ylog=False, \n",
    "                 fft_xlim=None, fft_ylim=None):\n",
    "    ## Plots a Single-Sided, normalized frequency space representation\n",
    "    ## of a time series y with sampling rate fsamp\n",
    "\n",
    "    ## Compute the FFT of the signal using NumPy's FFT implementation\n",
    "    freqs = np.fft.rfftfreq(len(y), 1/fsamp)\n",
    "    fft_vals = np.fft.rfft(y)\n",
    "\n",
    "    ## Plot the spectrum\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "    ax.plot(freqs, abs(fft_vals))\n",
    "\n",
    "    ax.set_xlabel('Freq (Hz)')\n",
    "    ax.set_ylabel('|Y(freq)|')\n",
    "    \n",
    "    ax.set_title('Frequency Domain Representation')\n",
    "\n",
    "    ## Set the axes limits if desired\n",
    "    if fft_xlim is not None:\n",
    "        ax.set_xlim(*fft_xlim)\n",
    "    if fft_ylim is not None:\n",
    "        ax.set_ylim(*fft_ylim)\n",
    "\n",
    "    ## Set the axes to be log scale if desired\n",
    "    if xlog:\n",
    "        ax.set_xscale('log')\n",
    "    if ylog:\n",
    "        ax.set_yscale('log')\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTimeAndSpectrum(y, fsamp, xlog=True, ylog=False,\n",
    "                        sig_xlim=None, sig_ylim=None,\n",
    "                        fft_xlim=None, fft_ylim=None):\n",
    "    # Plots a Single-Sided, normalized frequency space representation\n",
    "    # of a time series y with sampling rate fsamp alongside its time series\n",
    "\n",
    "    nsamp = len(y)\n",
    "\n",
    "    ## Create time vector for the signal, assuming the signal starts at t=0\n",
    "    ## and is sampled at 1/fsamp intervals. The result has units of seconds.\n",
    "    time_vector = np.linspace(0, nsamp-1, nsamp) * (1/fsamp)\n",
    "\n",
    "    ## Compute the FFT of the signal using NumPy's FFT implementation\n",
    "    freqs = np.fft.rfftfreq(len(y), 1/fsamp)\n",
    "    fft_vals = np.fft.rfft(y)\n",
    "\n",
    "    fig, ax = plt.subplots(2,1, figsize=(6,8))\n",
    "\n",
    "    ## Plot the signal as a function of time\n",
    "    ax[0].set_title('Time Domain Representation')\n",
    "    ax[0].plot(time_vector, y)\n",
    "    ax[0].set_xlabel('Time (seconds)')\n",
    "    ax[0].set_ylabel('Signal Amplitude')\n",
    "\n",
    "    ## Set the axes limits if desired\n",
    "    if sig_xlim is not None:\n",
    "        ax[0].set_xlim(*sig_xlim)\n",
    "    if sig_ylim is not None:\n",
    "        ax[0].set_ylim(*sig_ylim)\n",
    "\n",
    "    ## Plot the spectrum\n",
    "    ax[1].set_title('Frequency Domain Representation')\n",
    "    ax[1].plot(freqs, abs(fft_vals))\n",
    "    ax[1].set_xlabel('Frequency (Hz)')\n",
    "    ax[1].set_ylabel('Spectrum |Y(freq)|')\n",
    "\n",
    "    ## Set the axes limits if desired\n",
    "    if fft_xlim is not None:\n",
    "        ax[1].set_xlim(*fft_xlim)\n",
    "    if fft_ylim is not None:\n",
    "        ax[1].set_ylim(*fft_ylim)\n",
    "\n",
    "    ## Set the axes to be log scale if desired\n",
    "    if xlog:\n",
    "        ax[1].set_xscale('log')\n",
    "    if ylog:\n",
    "        ax[1].set_yscale('log')\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we play with these functions, let's generate a test array of FFT frequencies and take a look at it to better understand what's going"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamp = len(samps)\n",
    "test_freqs = np.fft.rfftfreq(nsamp, 1/fsamp)\n",
    "\n",
    "print(f'Sampling Fruqeuncy : {fsamp:0.1f} Hz')\n",
    "print(f'Nyquist Frequency  : {fsamp/2:0.1f} Hz')\n",
    "print(f'Total Samples      : {nsamp:0.1f}')\n",
    "print(f'Total Time         : {time_seconds:0.1f} sec')\n",
    "print(f'Lowest Frequency   : {test_freqs[1]:0.3g} Hz')\n",
    "print('FFT Frequencies    :')\n",
    "print(test_freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that this gives an array of linearly spaced frquencies starting at 0, up to 11,025 Hz which is the Nyquist frequency, i.e. the highest frequency that the FFT can resolve given the sampling rate.\n",
    "\n",
    "The spacing of the frequency bins (and the lowest frequency the FFT can resolve) is given by 1/(total_time).\n",
    "\n",
    "Now let's plot a spectrum!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TRY PLAYING WITH THE ARGUMENTS OF THIS FUNCTION to see how the plot changes\n",
    "## most especially the xlog and ylog arguments which change the scaling of the plot\n",
    "plotSpectrum(samps, fsamp, fft_xlim=[2, 2e4], xlog=True, ylog=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions for Discussion\n",
    "\n",
    "#### 1.1 What features of the music can be understood by the time domain plot? How well can these features be determined by just listening to the music?\n",
    "\n",
    "#### 1.2 What features of the music can be understood by the frequency domain plot? How well can these features be determined by just listening to the music? For example, can you associate specific sounds or instruments in the music with peaks in the frequency space plot?\n",
    "\n",
    "#### 1.3 Now choose a different music sample and compare/contrast the frequency space representation of the music. Does this make sense with what you hear from both files?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Fourier Transform\n",
    "\n",
    "The frequency space plot above was created using a widely applicable mathematical tool known as the Fourier Transform. A \"transform\" in math converts a function of one variable into a function of a different variable, and in particular the Fourier transform gives us our original function in terms of its various frequency components. Information about the distribution and magnitude of frequencies that make up a signal is often way more useful for both studying and processing the data you have collected.\n",
    "\n",
    "You will explore the mathematical formalism of this method in future classes (probably multiple times), but for this lab, we want to develop an intuition for how time series signals look in frequency space, starting with simple examples.\n",
    "\n",
    "## A Note On Finite Sampling Rates\n",
    "\n",
    "Because a truly continuous function would require infinitely many points to describe it, any digital waveform processing must rely on sampling the signal at a finite set of points such that we don't lose any (important) information about the signal we are reading. This can be accomplished with a sampling rate (samples per second) higher than twice the largest frequency present in the signal, a result in signal processing theory known as Nyquist's theorem. When a signal is under-sampled (the sampling rate is lower than twice the signal frequency), we end up capturing a wave that is different from the original one, an effect known as aliasing. The figure below demonstrates this effect, where the sampled points (the black dots) determine the measured signal and the under-sampled signal leads to the incorrect wave. Because humans can hear in a frequency band (range) from about 20-20,000 Hz, a typical sampling rate for music is 44.1 kHz, so the Nyquist frequency is slightly above the band of human perception.\n",
    "\n",
    "Another consequence of converting a continuous signal to a digital format made up finite samples is that a discrete version of the Fourier Transform has to be applied. This method converts a sequence of time series sampled data into an equally sized sequence of frequency space data. An efficient algorithm for computing the Discrete Fourier Transform, known as the Fast Fourier Transform (FFT), is what we have used for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=os.path.join('figures', 'aliasing.PNG')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note also that the image looks \"blurry\" because it's _spatially_ undersampled and thus aliased. The pixel density (like the spacing of time-domain samples) is too large, so we can't recover the underlying spatial oscillations due to the typeset letters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Sine Wave\n",
    "\n",
    "We can see from the plot below that a wave with a single frequency has a very simple frequency space representation as a very narrow peak at that frequency. In real life, you could interpret this kind of signal as a pure tone, like one you would create when playing a single note on a piano. Note that while theoretically the peak in frequency space should be infinitely narrow, there is always some broadening of this peak due to the finite sampling rates mentioned above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Define a sampling frequency and an associated time vector \n",
    "## spanning one second.\n",
    "fsamp_sine = 200  \n",
    "t = np.arange(0, 1, 1.0/fsamp_sine)\n",
    "\n",
    "## Construct a signal of interest with some chosen frequency\n",
    "f = 10.0\n",
    "sine = np.sin(2*np.pi*f*t)\n",
    "\n",
    "## Plot the signal and its spectrum\n",
    "plotTimeAndSpectrum(sine, fsamp_sine, xlog=False, ylog=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Sine Waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Define a sampling frequency and an associated time vector \n",
    "## spanning one second.\n",
    "fsamp_multi = 500\n",
    "t = np.arange(0, 1, 1.0/fsamp_multi) \n",
    "\n",
    "## Constrcut three signals with different frequencies\n",
    "f1 = 5.0\n",
    "sine1 = np.sin(2*np.pi*f1*t)\n",
    "\n",
    "f2 = 25.0\n",
    "sine2 = 0.5*np.sin(2*np.pi*f2*t)\n",
    "\n",
    "f3 = 50.0\n",
    "sine3 = 0.25*np.sin(2*np.pi*f3*t)\n",
    "\n",
    "## Create a superposition of the three signals and then plot it\n",
    "sig = sine1 + sine2 + sine3\n",
    "plotTimeAndSpectrum(sig, fsamp_multi, xlog=False, ylog=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### White Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "White noise in the time domain is just random numbers following a normal distribution. The resulting spectrum is flat across all frequencies, and is easily seen when plotted on a log-log scale.\n",
    "\n",
    "Note that while there is equal power at all frequencies in true white noise, when we generate a finite number of samples with a finite sampling rate, we see some variation in the power at different frequencies, and this variation increases as the frequency increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a sampling frequency and an associated time vector \n",
    "## spanning one second.\n",
    "fsamp_noise = 1000.0\n",
    "t = np.arange(0, 1, 1.0/fsamp_noise)\n",
    "\n",
    "## Generate some normally distributed random numbers to simulate white noise.\n",
    "rng = np.random.default_rng()\n",
    "rand_sig = rng.standard_normal(len(t))\n",
    "\n",
    "## Plot the white noise in both time and frequency domain.\n",
    "plotTimeAndSpectrum(rand_sig, fsamp_noise, xlog=True, ylog=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Square Wave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A square wave has fixed periodicity, but is not purely sinusoidal. Let's investigate its spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a sampling frequency and an associated time vector \n",
    "## spanning one second.\n",
    "fsamp_square = 1000.0\n",
    "t = np.arange(0, 1, 1.0/fsamp_square)\n",
    "\n",
    "## Construct a square wave signal using the important scipy.signal function\n",
    "f = 25.0\n",
    "square_wave = square(2 * np.pi * f * t)\n",
    "\n",
    "## Plot the square wave in both time and frequency domain.\n",
    "plotTimeAndSpectrum(square_wave, fsamp_square, xlog=False, ylog=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions for Discussion\n",
    "\n",
    "#### 2.1 For each of the three signals above (not including the single sine wave): Was one representation of the data more informative than the other? Is there information that you can understand from one representation that you can't from the other?\n",
    "\n",
    "#### 2.2 For the square wave signal, how do you think the frequency component with the largest magnitude relates to the frequency of the square wave as a whole? \n",
    "\n",
    "#### 2.3 Given your answer to 2.2, how would you then interpret the higher frequency components with smaller amplitude and their contribution to the square wave shape?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Signal Filtering\n",
    "\n",
    "Now we will apply our understanding of frequency space and perform signal manipulation that suppresses certain frequencies while not disturbing others. This kind of signal filtering is useful, for example, when the signal of interest is separated from the noise in the data in frequency space, and so a suitable filter can remove the noise without removing the important signal. \n",
    "\n",
    "Two kinds of filters we will consider are \"low-pass\" and \"high-pass\" filters, which, like the names suggest, allow signals below or above a certain cut-off frequency to pass through while suppressing all other frequencies. An example of a low-pass filter with a cut-off frequency of 50 Hz is plotted below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Choose a cutoff frequency and generate some filter coeefficients using the \n",
    "## scipy.signal module and Butterworth filter design with some defined order.\n",
    "## The order of the filter determines how quickly the filter rolls off after the\n",
    "## cutoff frequency. Higher order filters roll off more quickly, but may introduce\n",
    "## more distortion to the signal. You can test this by changing the value!\n",
    "f_cutoff = 50\n",
    "filter_order = 1\n",
    "b, a = signal.butter(filter_order, f_cutoff, 'low', analog=True)\n",
    "\n",
    "## Compute the frequency response of the filter\n",
    "w, h = signal.freqs(b, a)\n",
    "\n",
    "## Plot the frequency response\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "ax.semilogx(w, abs(h), lw=3)\n",
    "ax.set_title('Low-Pass filter frequency response')\n",
    "\n",
    "ax.set_xlabel('Frequency [Hz]')\n",
    "ax.set_ylabel('Amplitude retention')\n",
    "\n",
    "ax.grid(which='both', axis='both')\n",
    "ax.axvline(f_cutoff, color='green') # cutoff frequency\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this low-pass filter performs on the square wave we studied above.\n",
    "\n",
    "Also, you should make sure to look at both linear and logarithmic scaling for the vertical axis of the spectrum to observe some \"non-ideal\" behavior of the filter. How significant does the non-ideal behavior appear relative to the signal we care about?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Try changing these values to how the filtered signal changes\n",
    "f_cutoff = 50\n",
    "filter_order = 1\n",
    "\n",
    "## Change this variable from \"lp\" to \"hp\" to turn this into a high-pass filter\n",
    "filter_type = 'lp'\n",
    "sos = signal.butter(filter_order, f_cutoff, filter_type, fs=1000, output='sos')\n",
    "\n",
    "## Filter the square wave signal using the filter coefficients\n",
    "filtered_sig = signal.sosfilt(sos, square_wave)\n",
    "\n",
    "## Plot the filtered signal in both time and frequency domain.\n",
    "plotTimeAndSpectrum(filtered_sig, 1000, xlog=False, ylog=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question for Discussion\n",
    "\n",
    "#### 3.1 How does the low-pass-filtered square wave differ from the unfiltered wave in the time domain and the frequency domain? If this changes your understanding of the frequency space form of the square wave, make sure to go back and re-answer questions 2.2/2.3. Hint: if this question isn't making sense, try switching the filter type in the cell above to a high-pass filter and see what remains of the square wave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will return to our music files, and see how high-pass filtering changes how the music sounds, as well as how it changes the frequency space representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vary the cutoff frequency below for question 4.2\n",
    "f_cutoff = 2000\n",
    "\n",
    "## Optional frequency band to use for band-pass or band-stop filtering\n",
    "f_band = [100, 2000]\n",
    "\n",
    "## Here we can use a higher order filter to get a steeper roll-off\n",
    "filter_order = 4\n",
    "\n",
    "## Construct a filter using the cutoff and filter order specified above.\n",
    "## You could also try using a different filter type, such as \"lp\" for \n",
    "## low-pass. If you want to try a band-pass or band-stop filter, you'll \n",
    "## need to change the filter type to \"bp\" or \"bs\" and specify the \n",
    "## frequency band of interest, instead of a single cutoff frequency.\n",
    "filter_type = 'hp'\n",
    "sos = signal.butter(filter_order, f_cutoff, filter_type, fs=fsamp, output='sos')\n",
    "\n",
    "## Filter our audio signal (which was defined as \"samps\" above)\n",
    "filtered_sig = signal.sosfilt(sos, samps)\n",
    "\n",
    "## Plot the filtered signal in both time and frequency domain.\n",
    "plotTimeAndSpectrum(filtered_sig, fsamp, fft_xlim=[2, 2e4], xlog=True, ylog=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Play the filtered audio signal\n",
    "Audio(filtered_sig, rate=fsamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions for Discussion\n",
    "\n",
    "#### 4.1 Is the effect of the filter more clear in the time domain or the frequency domain?\n",
    "\n",
    "#### 4.2 How did the sound of the music change after filtering? Does this change agree with your intuition? Try varying the cut-off frequency in the code above to see when this effect becomes more or less significant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kipac_physics89L",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
