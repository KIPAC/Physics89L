{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6278746c",
   "metadata": {},
   "source": [
    "# More examples of model fitting (and how to do it poorly)\n",
    "\n",
    "### Goals:\n",
    "\n",
    "1. To understand how spectral data is used to estimate the Doppler shift (and speed) of distant galaxies.\n",
    "2. To be amazed that galaxies can be moving so quickly.\n",
    "3. To try fitting spectral data from the Sloan Digital Sky Survey (SDSS).\n",
    "4. To understand some of the pitfalls in fitting data.\n",
    "\n",
    "### Timing\n",
    "\n",
    "1. Try to finish this notebook in 30-35 minutes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3090392",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import scipy.optimize as optimize\n",
    "import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "952644ae",
   "metadata": {},
   "source": [
    "# Sloan Digital Sky Survey\n",
    "\n",
    "The Sloan Digital Sky Survey ([Project page](https://www.sdss.org/), [Wikipedia](https://en.wikipedia.org/wiki/Sloan_Digital_Sky_Survey)) truly changed the way we understand the universe.  \n",
    "\n",
    "Over the course of 20 years, SDSS observed 35% of the sky and catalogued about 1 billion stars and galaxies.\n",
    "\n",
    "In addition to taking images of such a large part of the sky, SDSS also measures the spectrum of the light from over 4 million objects.  \n",
    "\n",
    "The spectra are obtained by feeding an individual optical fiber for each target through a hole drilled in an aluminum plate.  The light from the fiber is then passed into a diffraction grating to separate out the different wavelengths. The diffracted light was then directed to an array of sensors, so that each sensor measured the amount of light at a different wavelength.\n",
    "\n",
    "Each hole is positioned specifically for a selected target, so every field in which spectra are to be acquired requires a unique plate. In spectroscopic mode, the telescope tracks the sky in the standard way, keeping the objects focused on their corresponding fiber tips. \n",
    "\n",
    "Here is a picture of one such aluminum plate:\n",
    "\n",
    "<div>\n",
    "<img src=\"figures/plate-sdss.jpg\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "We are going to be looking at the data from one fiber for one plate.  \n",
    "\n",
    "We can measure the distance of objects by taking advantage of the Doppler shift and what we know about atomic emission lines. Atomic transitions result in the emission of known wavelengths of light. Because the targets are moving with respect to earth, these wavelengths will be shifted. We can measure this Doppler shift of the light from a given target object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4356c190",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(open(\"../data/sds_galaxy.txt\", 'rb'), usecols=range(3))\n",
    "\n",
    "# This is how we pull out the data from columns in the array.\n",
    "\n",
    "# They put the data in angstroms, let's use nanometers instead. 1 angstrom = 0.1 nm\n",
    "wavelength = data[:,0]*0.1\n",
    "sfd = data[:,1]\n",
    "best_fit = data[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e414e63",
   "metadata": {},
   "source": [
    "`sfd` above refers to the \"spectral flux density\", which is the amount of electromagnetic energy received by the detector per unit area, per unit time, per unit wavelength. The units are $\\frac{{\\rm erg}}{{\\rm cm}^{2}s^{1}{{\\rm angstrom}}^{1}}$ (which we'll omit in the plots below for the sake of brevity).\n",
    "\n",
    "You can think of this as the power from a narrow wavelength band that would be seen by a 1 cm$^2$ detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f692d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(wavelength, best_fit)\n",
    "plt.xlabel(r\"$\\lambda$ [nm]\")\n",
    "plt.ylabel(\"Spectral flux density (sfd)\")\n",
    "plt.title(\"A spectrum from SDSS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d62a453",
   "metadata": {},
   "source": [
    "### $H\\alpha$ line\n",
    "\n",
    "The brightest line in this spectrum is the [hydrogen $\\alpha$ line](https://en.wikipedia.org/wiki/H-alpha), which is emitted when an electron de-excites from the $n=3$ to $n=2$ energy level of the hydrogen atom. In vacuum in the rest frame of the hydrogen atom, the H-alpha line has a wavelength of 656.46 nm.\n",
    "\n",
    "Let's use this dataset to make a quick estimate of the wavelength of the H $\\alpha$ line, the redshift of the object, and its velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127957b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate which item in the array has the largest value\n",
    "peak_idx = np.argmax(sfd)\n",
    "# pick out the corresponding wavelength\n",
    "peak_wl = wavelength[peak_idx]\n",
    "print(f\"The peak wavelength in data is {peak_wl:0.2f} nm\")\n",
    "\n",
    "H_alpha = 656.4614\n",
    "print(f\"In the rest frame of the H atom, the H alpha line is at {H_alpha:.4f} nm\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca772fcc",
   "metadata": {},
   "source": [
    "Let's define a function to calculate the redshift of the object, defined as \n",
    "$$z = \\frac{\\lambda_\\mathrm{observed}}{\\lambda_\\mathrm{emitted}} - 1,$$\n",
    "\n",
    "and the velocity divided by the speed of light $c$, or $\\beta=\\frac{v}{c}$ value:\n",
    "\n",
    "$$\\beta = \\frac{1-\\lambda_\\mathrm{emitted}^2/\\lambda_\\mathrm{observed}^2}{1+\\lambda_\\mathrm{emitted}^2/\\lambda_\\mathrm{observed}^2}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5c8f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def redshift(l_sdss,l_0):\n",
    "    return (l_sdss/l_0)-1\n",
    "\n",
    "def beta(l_sdss,l_0):\n",
    "    r2 = pow(l_sdss/l_0,2)\n",
    "    return (1 - (1/r2))/(1 + (1/r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f12802b",
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = redshift(peak_wl,H_alpha)\n",
    "print(f\"This corresponds to a redshift of {z1:.5f}\")\n",
    "b = beta(peak_wl,H_alpha)\n",
    "print(f\"Based on this line we estimate that this object is moving away from us with a velocity of {b:0.4f} c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359289aa",
   "metadata": {},
   "source": [
    "### Question for discussion\n",
    "\n",
    "#### 4.1 About how far away is this object?  You can estimate it based on Hubble's law, $v = H_0 d$. Please show your work.\n",
    "\n",
    "For the value of the Hubble parameter you can use $H_0 = 70 \\, \\frac{{\\rm km}\\,}{{\\rm s}} \\cdot {\\rm Mpc}^{-1}$.\n",
    "\n",
    "The speed of light is about $c = 3 \\times 10^8$ m/s.\n",
    "\n",
    "1 parsec (pc) = 3.26 light years (ly).\n",
    "\n",
    "Note that this computation leaves out some subtleties, like what we mean by \"how far away\", as in \"how far away when the light was emitted?\" or \"how far away right now?\", and that isn't even getting into the issues that come up when we consider relativity or the acceleration of the Universe. But at least it gives you a distance scale to think about.\n",
    "\n",
    "If you are curious about the details, have a look at this: [Ned Wright's Cosmological Distance Calculator](http://www.astro.ucla.edu/~wright/CosmoCalc.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3faa56",
   "metadata": {},
   "source": [
    "### Zoom in on $H \\alpha$ line\n",
    "\n",
    "If we zoom in on the line, we see it is actually three lines.   That complicates things for trying to fit the lines to a model, as we would have to include all three lines in our model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b6c42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout_wl = wavelength[peak_idx-50:peak_idx+50]\n",
    "cutout_sfd = sfd[peak_idx-50:peak_idx+50]\n",
    "plt.plot(cutout_wl, cutout_sfd)\n",
    "plt.xlabel(r\"$\\lambda$ [nm]\")\n",
    "plt.ylabel(\"Spectral flux density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe89abe9",
   "metadata": {},
   "source": [
    "Instead, let's focus on fitting a simpler case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eadda91",
   "metadata": {},
   "source": [
    "### The $H \\beta$ line.\n",
    "\n",
    "The brightest line near 500 nm is the $H \\beta$ line, the little sibling of the $H \\alpha$ line, which arises from the $n=4$ to $n=2$ transition. It is more isolated, making it a better choice for us to fit with a simple model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb9d4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (wavelength > 500) & (wavelength < 510)\n",
    "cutout_wl = wavelength[mask]\n",
    "cutout_sfd = sfd[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a3ce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cutout_wl, cutout_sfd)\n",
    "plt.xlabel(r\"$\\lambda$ [nm]\")\n",
    "plt.ylabel(\"Spectral flux density\")\n",
    "plt.title(r\"Data around the H$\\beta$ spectral line\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5377a6bf",
   "metadata": {},
   "source": [
    "# Our model\n",
    "\n",
    "Now we want to characterize this line. We would like to know the peak location, peak intensity, and width of the peak. Notice that the H$\\beta$ line is also on top of what looks like a flat background flux rate. How do we extract this information?\n",
    "\n",
    "We are going to fit this line to a model with two parts.\n",
    "\n",
    "   1. We will model this line itself as a unit Gaussian $ G(\\lambda | \\mu, \\sigma)$ times a prefactor that gives the height of the peak ($n$).  \n",
    "   2. We will model the background as a slope and offset.  To reduce the correlation between the two, we will define the offset at 500 nm. $p_0 + (\\lambda - 500) \\cdot p_1$.\n",
    "   \n",
    "This gives us a model with five parameters: $(n, \\mu, \\sigma, p_0, p_1)$.\n",
    "\n",
    "$m(\\lambda \\, | \\, n, \\mu, \\sigma, p_0, p_1) = n \\, G(\\lambda | \\mu, \\sigma) + p_0 + (\\lambda - 500) \\cdot p_1$.\n",
    "\n",
    "The next cell codes up the model and the functions we need for the fitting. This is just a slightly more complicated version of what we did in the first notebook, because this model has a few more parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1d985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gauss(x, n, mu, sigma):\n",
    "    return n*stats.norm(loc=mu, scale=sigma).pdf(x)\n",
    "\n",
    "def poly1(x, offset, slope):\n",
    "    return offset + (x-500)*slope\n",
    "\n",
    "def model_func(x, prefact, mu, sigma, offset, slope):\n",
    "    return Gauss(x, prefact, mu, sigma) + poly1(x, offset, slope)\n",
    "\n",
    "def generic_chi2(params, data_vals, model, x):\n",
    "    model_vals = model(x, *params)\n",
    "    return np.sum((data_vals - model_vals)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13061ed",
   "metadata": {},
   "source": [
    "### Initial guess\n",
    "\n",
    "Let's guess some initial values for the parameters and plot the model to see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aceb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_0 = 235.\n",
    "mu_0 = 505.8\n",
    "sigma_0 = 0.25\n",
    "offset_0 = 60.\n",
    "slope_0 = 0.\n",
    "\n",
    "init_pars = (n_0, mu_0, sigma_0, offset_0, slope_0)\n",
    "model_vals = model_func(cutout_wl, *init_pars)\n",
    "background_vals = poly1(cutout_wl, init_pars[3], init_pars[4])\n",
    "\n",
    "plt.plot(cutout_wl, cutout_sfd, 'k.', label=\"data\")\n",
    "plt.plot(cutout_wl, background_vals, 'm--', label=\"background model\")\n",
    "plt.plot(cutout_wl, model_vals, 'b', label=\"full model\")\n",
    "plt.xlabel(r'$\\lambda$ [nm]')\n",
    "plt.ylabel(r'Spectral flux density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c884267",
   "metadata": {},
   "source": [
    "# Getting the cost function\n",
    "\n",
    "First we are going to fit using a cost function that uses the full model to compare to the data.  \n",
    "\n",
    "Similar to what we did in the first notebook, we need to write a wrapper function that uses our specific data and takes only the model parameters as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302a1242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_cost_func(params):\n",
    "    return generic_chi2(params, cutout_sfd, model_func, cutout_wl)\n",
    "\n",
    "print(f\"Initial chi squared: {our_cost_func(init_pars):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da98c00",
   "metadata": {},
   "source": [
    "### Fitting the model\n",
    "\n",
    "Let's go ahead and fit the model and print out the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23350872",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = optimize.minimize(our_cost_func, x0=np.array(init_pars))\n",
    "fit_pars = result['x']\n",
    "model_fit = model_func(cutout_wl, *fit_pars)\n",
    "background_fit = poly1(cutout_wl, fit_pars[3], fit_pars[4])\n",
    "print(\"Best Fit ---------\")\n",
    "print(f\"Line Intensity: {fit_pars[0]:.1f} [spectral flux density units]\")\n",
    "print(f\"Line Peak Location: {fit_pars[1]:.4f} [nm]\")\n",
    "print(f\"Line Width: {fit_pars[2]:.4f} [nm]\")\n",
    "print(f\"Background at 500 nm: {fit_pars[3]:.2f} [sfd units]\")\n",
    "print(f\"Background slope: {fit_pars[4]:.2f} [sfd units / nm]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3cf4cf",
   "metadata": {},
   "source": [
    "### Plotting the fit results\n",
    "\n",
    "Let's make a plot of the data and the model, and let's break out the background part of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a65f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cutout_wl, cutout_sfd, 'k.', label=\"data\")\n",
    "plt.plot(cutout_wl, background_fit, 'm--', label=\"background model\")\n",
    "plt.plot(cutout_wl, model_fit, 'b', label=\"full model\")\n",
    "plt.xlabel(r\"$\\lambda$ [nm]\")\n",
    "plt.ylabel(\"Spectral flux density\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49591e25",
   "metadata": {},
   "source": [
    "### Questions for discussion\n",
    "\n",
    "#### 5.1 Before going further, it is important to make sure you understand the previous plot. Write a description of the plot, how we made it, and what each part means. How did we get from the previous plot, with the initial guess for the model parameters, to this one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7514f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "H_beta = 486.2721\n",
    "\n",
    "z2 = (fit_pars[1]/H_beta)-1\n",
    "print(f\"We fit the peak of the line at {fit_pars[1]:.4f} nm\")\n",
    "print(f\"In a vacuum, the H beta line is at {H_beta:.4f} nm\")\n",
    "\n",
    "z1 = redshift(fit_pars[1],H_beta)\n",
    "print(f\"This corresponds to a redshift of {z1:.5f}\")\n",
    "b = beta(fit_pars[1],H_beta)\n",
    "print(f\"Based on this line we estimate that this object is moving away from us with a velocity of {b:0.4f} c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b5c259",
   "metadata": {},
   "source": [
    "### How to do a bad fit, version 1, using a bad model\n",
    "\n",
    "Let's see what happens if we forget to include background model. To do that we are going to construct a cost function using just the Gaussian instead of the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf6a6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bad_cost_func(params):\n",
    "    return generic_chi2(params, cutout_sfd, Gauss, cutout_wl)\n",
    "\n",
    "init_pars_bad = (n_0, mu_0, sigma_0)\n",
    "model_fit_bad = Gauss(cutout_wl, *init_pars_bad)\n",
    "plt.plot(cutout_wl, cutout_sfd, 'k.', label=\"data\")\n",
    "plt.plot(cutout_wl, model_fit_bad, label=\"model\")\n",
    "plt.xlabel(r\"$\\lambda$ [nm]\")\n",
    "plt.ylabel(\"Spectral flux density\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7c2466",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_bad = optimize.minimize(bad_cost_func, x0=np.array(init_pars_bad))\n",
    "fit_pars_bad_1 = result_bad['x']\n",
    "model_fit_bad = Gauss(cutout_wl, *fit_pars_bad_1)\n",
    "plt.plot(cutout_wl, cutout_sfd, 'k.', label=\"data\")\n",
    "plt.plot(cutout_wl, model_fit_bad, label=\"model\")\n",
    "plt.xlabel(r\"$\\lambda$ [nm]\")\n",
    "plt.ylabel(\"Spectral flux density\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Best Fit ---------\")\n",
    "print(f\"Line Intensity: {fit_pars_bad_1[0]:.1f} [sfd units]\")\n",
    "print(f\"Line Peak Location: {fit_pars_bad_1[1]:.4f} [nm]\")\n",
    "print(f\"Line Width: {fit_pars_bad_1[2]:.4f} [nm]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a219d2",
   "metadata": {},
   "source": [
    "### Questions for discussion\n",
    "\n",
    "#### 6.1 What's the difference between this fit and the previous fit? How would you interpret this result?  Do the parameters make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b902c3e",
   "metadata": {},
   "source": [
    "### How to do a bad fit, version 2, using bad initial parameters\n",
    "\n",
    "Now we are going to use the full model again, but we will see what happens if we choose bad parameters for our initial guess.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c533772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same initial params, except offset the gaussian mean by 2 nm\n",
    "init_pars_bad_2 = (n_0, mu_0+2.0, sigma_0, offset_0, slope_0)\n",
    "model_fit_bad = model_func(cutout_wl, *init_pars_bad_2)\n",
    "\n",
    "plt.plot(cutout_wl, cutout_sfd, 'k.', label='data')\n",
    "plt.plot(cutout_wl, model_fit_bad, label='model')\n",
    "plt.xlabel(r\"$\\lambda$ [nm]\")\n",
    "plt.ylabel(\"Spectral flux density\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d4321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_bad_2 = optimize.minimize(our_cost_func, x0=np.array(init_pars_bad_2))\n",
    "fit_pars_bad_2 = result_bad_2['x']\n",
    "model_fit_bad_2 = model_func(cutout_wl, *fit_pars_bad_2)\n",
    "\n",
    "plt.plot(cutout_wl, cutout_sfd, 'k.', label=\"data\")\n",
    "plt.plot(model_fit_bad_2, label=\"model\")\n",
    "plt.xlabel(r\"$\\lambda$ [nm]\")\n",
    "plt.ylabel(\"Spectral flux density\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Best Fit ---------\")\n",
    "print(f\"Line Intensity: {fit_pars_bad_2[0]:.1f} [sfd units]\")\n",
    "print(f\"Line Peak Location: {fit_pars_bad_2[1]:.4f} [nm]\")\n",
    "print(f\"Line Width: {fit_pars_bad_2[2]:.4f} [nm]\")\n",
    "print(f\"Background at 500 nm: {fit_pars_bad_2[3]:.2f} [sfd units]\")\n",
    "print(f\"Background slope: {fit_pars_bad_2[4]:.2f} [sfd units / nm]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbd4e3f",
   "metadata": {},
   "source": [
    "### Questions for discussion\n",
    "\n",
    "#### 7.1 How would you interpret the fit result?  Do the parameters make sense?\n",
    "\n",
    "#### 7.2 This illustrates that it is often important to start with a reasonable initial guess. If we were fitting millions of spectra, we would want the program to make the initial guess instead of having to do it by hand.  How might you systematically make an initial guess for the a) line peak, b) the line width, c) the background at 500 nm, d) the background slope?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
