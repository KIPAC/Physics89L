{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbf5dee8",
   "metadata": {},
   "source": [
    "# Gaussian distributions: how to recognize them, and where they come from\n",
    "\n",
    "### Goals:\n",
    "\n",
    "1. To understand the basic properties of a Gaussian distribution (a.k.a. \"Normal Distribution\", a.k.a. \"Bell Curve\").\n",
    "2. To understand the parameters of the Gaussian distribution.\n",
    "3. To get an intuitive sense of why Gaussian distributions are so common in science, and what sorts of process might give rise to Gaussian distributions.\n",
    "4. To understand how and why Gaussian distributions are used to express statistical significance, and how to convert between Gaussian \"sigma\" and p-value.\n",
    "\n",
    "### Timing\n",
    "\n",
    "1. Try to finish this notebook in 35 minutes.\n",
    "\n",
    "### Question and Answer Template\n",
    "\n",
    "You can go to the link below, and do \"file\" -> \"make a copy\" to make yourself a google doc that you can use to fill in the answers to the question in this weeks notebooks.\n",
    "\n",
    "https://docs.google.com/document/d/1bmZwrVMNye_1oG1T88v1GhwWX1dXflY9gdxg8DVS7ks/edit?usp=drive_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9093ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b216aee",
   "metadata": {},
   "source": [
    "### New/important functions we will use in this module\n",
    "\n",
    "| Function Name            | What it does |\n",
    "| - | - |\n",
    "|    rng.poisson           | generates a random integer from a \"Poisson\" distribution |\n",
    "|    scipy.stats.norm      | Interact with a Gaussian distribution |\n",
    "|    plt.annotate          | Add text to a plot |  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f736990",
   "metadata": {},
   "source": [
    "# Gaussian distribution, aka Normal Distribution, aka Bell Curve\n",
    "\n",
    "A Gaussian distribution is a distribution defined by:\n",
    "\n",
    "$G(x | \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}$\n",
    "\n",
    "Where the notation $G(x | \\mu, \\sigma)$ means that:\n",
    "\n",
    "The function $G$ depends on $x$, $\\mu$ and $\\sigma$, but typically we provide $\\mu$ and $\\sigma$ to define a specific curve as a function of $x$.\n",
    "\n",
    "$x$ is what we sometimes call the \"independent variable\", while $\\mu$ and $\\sigma$ are sometimes called \"parameters\".  Basically, each set of values of $\\mu$ and $\\sigma$ defines a different curve.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56872525",
   "metadata": {},
   "source": [
    "If we take $\\mu = 0$ and $\\sigma = 1$ then the formula simplifies somewhat:\n",
    "\n",
    "$G(x | \\mu=0, \\sigma=1) = \\frac{1}{1\\sqrt{2\\pi}}e^{-\\frac{(x - 0)^2}{2*1^2}} = \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{x^2}{2}}$\n",
    "\n",
    "This is referred to as the \"standard normal distribution\" or \"unit-Gaussian\" (more on this later). \n",
    "\n",
    "Let's write a function to compute a Gaussian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726b3a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, mu=0., sigma=1.):\n",
    "    prefactor = 1 / ( sigma * np.sqrt(2*np.pi) )\n",
    "    exponent = -(x - mu)**2 / (2*sigma**2)\n",
    "    return prefactor * np.exp(exponent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444661e7",
   "metadata": {},
   "source": [
    "Let's plot that.  We are going to use the equation I wrote out above, and also the 'scipy.stats.norm' function to do it and then compare the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7d97c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate an array of values to plot/check\n",
    "x_vals = np.linspace(-6, 6, 601)\n",
    "\n",
    "## Compute the values of the Gaussian function with a mean of 0\n",
    "## and a standard deviation of 1, using the values of x from\n",
    "## the above array\n",
    "y_vals_check = gaussian(x_vals, mu=0, sigma=1)\n",
    "\n",
    "## Do the same thing, but using the scipy.stats.norm functionn \n",
    "## Note that the arguments have different names, and the \n",
    "## function is called in a slightly different manner i.e., you \n",
    "## specify the parameters in the call to norm() and then the \n",
    "## independent variable in the call to pdf()\n",
    "y_vals = stats.norm(loc=0, scale=1).pdf(x_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aebd56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate a figure and axis object for more control\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "## Plot the two sets of values, making one a thicker dashed\n",
    "## line so that we can see both at the same time. To ensure the\n",
    "## plotting order is correct (thin solid line on top of thick\n",
    "## dashed line), we will use the 'zorder' argument)\n",
    "plt.plot(x_vals, y_vals, lw=2, label=\"scipy.stats version\", zorder=5)\n",
    "plt.plot(x_vals, y_vals_check, lw=4, ls='--', label=\"function\", zorder=4)\n",
    "plt.legend()\n",
    "plt.title(\"My first Gaussian\")\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$G(x | \\mu=0, \\sigma=1)$')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d75bd9d2",
   "metadata": {},
   "source": [
    "### Properties of a Gaussian\n",
    "\n",
    "Some properties we can infer just by examining the formula:\n",
    "\n",
    "1. Since $\\frac{(x-\\mu)^2}{2\\sigma^2}$ is always postive, and there is a minus sign in front of it, the term in the exponent is always zero or negative.  That means the maximum is when that term is zero, i.e., when $x = \\mu$. Thus, $\\mu$ gives the location of the peak of the distribution.  \n",
    "2. Since the term in the exponent, $\\frac{(x - \\mu)^2}{2\\sigma^2}$, is symmetric about $\\mu$, the Gaussian distribution is symmetric about $\\mu$, i.e., $G(x = \\mu + a | \\mu, \\sigma) = G(x = \\mu - a | \\mu, \\sigma)$\n",
    "3. The distribution is always positive, i.e., $e^{-x} > 0$ for all x.\n",
    "4. The distribution goes towards zero pretty quickly where $(x - \\mu)^2$ is bigger than $\\sigma$.  \n",
    "\n",
    "And we can confirm those by looking at the plot. \n",
    "\n",
    "One thing to note:  the peak of the distribution is at $\\frac{1}{\\sqrt{2\\pi}} \\sim 0.4$.  This is to ensure that the integral of the distribution is 1, i.e.,\n",
    "\n",
    "$\\int_{-\\infty}^{\\infty} G(x | \\mu, \\sigma) = 1$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dded579",
   "metadata": {},
   "source": [
    "### What happens when we change the parameters?\n",
    "\n",
    "First, lets plot a series of Gaussians with different values of $\\mu$.\n",
    "\n",
    "Then we will plot a series of Gaussians with different values of $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb449e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate a figure and axis object for more control\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "## Loop over some values of the mean and plot the associated\n",
    "## Gaussian functions. Note that we are using the same value of\n",
    "## the standard deviation for all of the functions so that we\n",
    "## assess how the mean affects the shape of the Gaussian\n",
    "for mu in np.linspace(-3, 3, 7):\n",
    "    ax.plot(x_vals, gaussian(x_vals, mu=mu), label=rf\"$\\mu = {mu:0.1f}$\")\n",
    "\n",
    "ax.set_xlabel(r'$x$')\n",
    "ax.set_ylabel(r'$G(x | \\mu, \\sigma=1)$')\n",
    "\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a47bd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate a figure and axis object for more control\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "## Loop over some values of the standard deviation and plot.\n",
    "## Note that we are using the same value of the mean\n",
    "for sigma in np.linspace(0.4, 1.6, 7):\n",
    "    ax.plot(x_vals, gaussian(x_vals, sigma=sigma), label=rf\"$\\sigma = {sigma:0.1f}$\")\n",
    "\n",
    "ax.set_xlabel(r'$x$')\n",
    "ax.set_ylabel(r'$G(x | \\mu=0, \\sigma)$')\n",
    "\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0851fb",
   "metadata": {},
   "source": [
    "### Questions for discussion\n",
    "\n",
    "#### 1.1 Why do all the Gaussians in the first example have the same height, while the ones in the second example do not?  Answer both in terms of the formula, and in plain english. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5112a6d3",
   "metadata": {},
   "source": [
    "### A comment on nomenclature / jargon:\n",
    "\n",
    "We can always shift and rescale a Gaussian by setting $x' = \\frac{x - \\mu}{\\sigma}$ so that the quantity in the exponent becomes \n",
    "\n",
    "$e^{-(\\frac{x'}{2})^2}$\n",
    "\n",
    "In practical terms, this means that if we have some quantity that we think is described by a Gaussian, we can subtract off the mean and divide by the standard deviation and it will now be described by a so-called \"unit-Gaussian\" i.e., a Gaussian with $\\mu =0$ and $\\sigma = 1$.\n",
    "\n",
    "Because of this fact, there is a pretty standard jargon to refer to the x-axis of a Gaussian as though it had units of $\\sigma$.  I.e., we say things like \"a $3 \\sigma$ outlier\" all the time.  This would mean that, for that data point, $x - \\mu = 3 \\sigma$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34c677a",
   "metadata": {},
   "source": [
    "# Why a Gaussian?\n",
    "\n",
    "We are learning about Gaussians because they occur all the time in nature. \n",
    "\n",
    "In short, a Gaussian distribution is what you get when a lot of random effects add up together, no matter what process causes these random effects, or, in statistical terms, no matter what probability distribution the individual samples are drawn from. This means that even if the individual samples don't follow a Gaussian distribution, the sum of those samples will tend to look more and more like a Gaussian distribution as the sample size gets larger. This is known as the central limit theorem. The central limit theorem is important because it allows us to make statistical inferences about a population based on a sample of data, even if we don't know much about the underlying population's distribution.\n",
    "\n",
    "We are going to illustrate this with 2 different examples, where the individual samples are generated with a uniform and a Poisson distribution, respectively, and show that we get very Gaussian-looking distributions.\n",
    "\n",
    "1.  We are going to generate 10000 sets of 12 random numbers from a uniform distribution between 0 and 1, i.e., there's no preference for certain numbers between 0 and 1, and add each set together. This will give us 10000 numbers between 0 and 12, and we will see that their distribution looks a lot like a Gaussian with $\\mu = 6$ and $\\sigma = 1$. \n",
    "\n",
    "2.  We are going to generate 10000 trials of an experiment, where on average, we expect to see 100 \"events\" in each trial. \"Events\" could be pretty much anything that you can count: nuclear decays, detections of distant supernovae, cars passing through an intersection, etc. The number of events in each individual trial therefore follows the Poisson distribution. This will give us 10000 numbers that are distributed very close to a Gaussian with $\\mu = 100$ and $\\sigma = 10$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f4bf91",
   "metadata": {},
   "source": [
    "#### A Gaussian as the sum of 12 uniformly distributed numbers between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813dbe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## '42' is a arbitrary seed for the quasi-random number generator \n",
    "## that numpy uses under the hood. This is a good practice to \n",
    "## ensure that the results are reproducible, because you will \n",
    "## get the same \"random\" numbers each time you run the code.\n",
    "## Random number generators are super interesting and worth \n",
    "## reading about if you're curious. They are not truly random, \n",
    "## but pull values from a deterministic sequence that is \n",
    "## incredibly long and complex and simulates randomness.\n",
    "rng = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ed5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This line tells numpy to generate 120000 random numbers \n",
    "## uniformly distributed betweeen 0 and 1, and split into \n",
    "## 10000 groups of 12. The rng.uniform() function can also take \n",
    "## upper and lower limits as arguments.\n",
    "randomNumbers = rng.uniform(size=(10000, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18d5050",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Inspect the distribution of one set (change this number\n",
    "## to look at any of the other sets!)\n",
    "set_index = 1337\n",
    "\n",
    "## Instantiate a figure and axis object for more control\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.hist(randomNumbers[set_index],bins=np.linspace(0,1,20))\n",
    "ax.set_xlabel(r'Value')\n",
    "ax.set_ylabel(r'Counts')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62491eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This line takes the sum of each group of 12, giving us a total \n",
    "## of 10000 numbers. The \"axis=1\" argument tells numpy to sum \n",
    "## along the second axis of the array, which is the axis that \n",
    "## corresponds to the 12 numbers in each group.\n",
    "sums = np.sum(randomNumbers, axis=1)\n",
    "\n",
    "print(\"Some numbers are \", sums)\n",
    "print(f\"And we have {sums.size} numbers total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c25818",
   "metadata": {},
   "source": [
    "##### Once you read this block of code and execute it, make sure to read the text immediately after!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804ea161",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate an array of possible sum values, ranging from 0\n",
    "## to 12 which represent the possible sums of 12 numbers\n",
    "## uniformly distributed between 0 and 1\n",
    "xvals = np.linspace(0,12,121)\n",
    "\n",
    "## Instantiate a figure and axis object for more control\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "## Plot a histogram of our sums\n",
    "ax.hist(sums, bins=xvals)\n",
    "\n",
    "## Plot some vertical lines for the mean and +-1 std. dev.\n",
    "ax.axvline(x=np.mean(sums), ls='--', c='k')\n",
    "ax.axvline(x=np.mean(sums)+np.std(sums), ls=':', c='k')\n",
    "ax.axvline(x=np.mean(sums)-np.std(sums), ls=':', c='k')\n",
    "\n",
    "## With an appropriate prefactor, compute the Gaussian\n",
    "## that we would expect to match our histogram\n",
    "prefactor = 10000 * 0.1\n",
    "myGauss = prefactor*stats.norm(loc=6, scale=1).pdf(xvals)\n",
    "ax.plot(xvals, myGauss, label=r'$G(x | \\mu=6, \\sigma=1)$')\n",
    "\n",
    "ax.set_xlabel(r'sum of 12 random numbers [a.u.]')\n",
    "ax.set_ylabel(r'Counts [per 0.1 a.u.]')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "ax.annotate(f\"mean = {np.mean(sums):0.2f}\", (10, 320))\n",
    "ax.annotate(f\"std = {np.std(sums):0.2f}\", (10, 300))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815eac87",
   "metadata": {},
   "source": [
    "Note: The Gaussian is defined so that it integrates to 1.  But:\n",
    "* We generated 10000 numbers\n",
    "* Our histogram bins are 0.1 units wide, which changes the Riemann summation\n",
    "\n",
    "So, to get the height of the curve to match the histogram we need to multiply by a prefactor of 10000 * 0.1.\n",
    "\n",
    "This is sort of a \"boot-strap\" technique, as the more appropriate thing to do would be to normalize the histogram to represent a proper probability density function, rather than the other way around."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a11ae2",
   "metadata": {},
   "source": [
    "### Questions for discussion\n",
    "\n",
    "#### 2.1 Notice in the figure above that the $\\mu$ and $\\sigma$ of the Gaussian that we chose are very close to the mean and standard deviation of the distribution of sums.  How do you think the parameters of the Gaussian should change if we added together more numbers, say 24 numbers instead of 12 numbers? (Hint: The variance of a uniform distribution from $a$ to $b$ is $\\frac{(b-a)^2}{12}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faca6b6",
   "metadata": {},
   "source": [
    "#### A Gaussian as the distribution of a (large) number of random occurences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32de7dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This line tells numpy to simulate 10000 trials of an \n",
    "## experiment where on average we expect to see 100 \"events\" \n",
    "## in each trial. \n",
    "## \"Events\" could be pretty much anything that you can count: \n",
    "##   - nuclear decays\n",
    "##   - detections of distant supernovae \n",
    "##   - cars passing through an intersection  \n",
    "nEvts = rng.poisson(lam=100, size=10000)\n",
    "\n",
    "## Then this line tells numpy to count how many numbers in each \n",
    "## group of 1000 are less that 0.1\n",
    "print(f\"Some numbers are {nEvts}\")\n",
    "print(f\"And we have {nEvts.size} numbers total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3249f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute an array of possible values for the number of events\n",
    "## that we would expect to see in each trial.\n",
    "xvals = np.linspace(50,150,101)\n",
    "\n",
    "## Instantiate a figure and axis object for more control\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "## Plot the histogram and some vertical lines for the mean and\n",
    "## +-1 std. dev., as before.\n",
    "ax.hist(nEvts, bins=xvals)\n",
    "ax.axvline(x=np.mean(nEvts), ls='--', c='k')\n",
    "ax.axvline(x=np.mean(nEvts)+np.std(nEvts), ls=':', c='k')\n",
    "ax.axvline(x=np.mean(nEvts)-np.std(nEvts), ls=':', c='k')\n",
    "\n",
    "## With an appropriate prefactor, compute the Gaussian\n",
    "## that we would expect to match our histogram\n",
    "myGauss = 10000*stats.norm(loc=100, scale=10).pdf(xvals)\n",
    "plt.xlabel(r'$n_{\\rm evt}$')\n",
    "plt.ylabel(r'Counts [per number]')\n",
    "plt.plot(xvals, myGauss, label=r'$G(x, \\mu=100, \\sigma=10)$')\n",
    "plt.legend()\n",
    "\n",
    "plt.annotate(f\"mean = {np.mean(nEvts):0.2f}\", (130, 330))\n",
    "plt.annotate(f\"std = {np.std(nEvts):0.2f}\", (130, 300))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb4f0aa",
   "metadata": {},
   "source": [
    "Note: The Gaussian is defined so that it integrates to 1.  But:\n",
    "* We generated 10000 numbers\n",
    "* Our histogram bins are now 1 unit wide, which changes the Riemann summation\n",
    "\n",
    "So, to get the height of the curve to match the histogram we need to multiply by a prefactor of 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8708451",
   "metadata": {},
   "source": [
    "### Questions for discussion\n",
    "\n",
    "#### 2.2 How do you think the distribution would look if we set a lower average number of events per trial (let's say 3)? Feel free to test it out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885d1cb3",
   "metadata": {},
   "source": [
    "# P-values and statistical significance\n",
    "\n",
    "### You want to pay very close attention here.\n",
    "\n",
    "One type of question that arises all the time in scientific data analysis is something along the lines of: \"Are we seeing a random fluctuation, or is this a real signal?\"  One of the ways in which we answer that question is by rephrasing it as: \"How likely (or unlikely) is it that truly random data could have fluctuated in such a way as to give us a result at least this suprising?\"   \n",
    "\n",
    "That is the concept of a p-value.  In words it is the probabilitly, given random data with no signal, to see an outlier at least as big as what we observed.\n",
    "\n",
    "If we believe that our data are distributed as a Gaussian, then mathematically, the probability of seeing an outlier equal to or larger than $x_0$ is\n",
    "\n",
    "$p(x_0) = 1 - \\int_{-\\infty}^{x_0} G(x | \\mu, \\sigma) dx$\n",
    "\n",
    "The scipy.stats package calls this quantity 'sf' for 'survival fraction'.\n",
    "\n",
    "Let's have a look at it, for a \"Unit Gaussian\". First let's generate some values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9804685",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate an array of values to plot/check\n",
    "x_vals = np.linspace(-6, 6, 601)\n",
    "\n",
    "## Compute the values of the Gaussian function with a mean of 0\n",
    "## and a standard deviation of 1, using the values of x from\n",
    "## the above array\n",
    "y_vals = gaussian(x_vals, mu=0, sigma=1)\n",
    "\n",
    "## Compute the values of the survival fraction for each of the\n",
    "## values of x from the above array\n",
    "y_sf = stats.norm(loc=0, scale=1).sf(x_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804350e1",
   "metadata": {},
   "source": [
    "Now let's plot all these things!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be68e6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate a figure and axis object for more control\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot(x_vals, y_vals, label=\"Gaussian\")\n",
    "ax.plot(x_vals, y_sf, label=\"Survival Fraction\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(r'$x$')\n",
    "ax.set_ylabel(r'$G(x | \\mu=0, \\sigma=1)$')\n",
    "ax.grid()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3413da16",
   "metadata": {},
   "source": [
    "The survival fraction (a.k.a. the p-value) goes to zero pretty quickly once you get out past about 1-2 times the standard deviation.  That is just saying that there isn't really a lot of stuff out in the tails of the Gaussian distribution.\n",
    "\n",
    "Let's switch to plotting the y-axis on a log scale to see what is going on out there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f61091",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate a figure and axis object for more control\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "#plt.plot(x_vals, y_vals, label=\"Gaussian\")\n",
    "ax.plot(x_vals, y_sf, label=\"Survival Fraction\")\n",
    "\n",
    "ax.set_xlabel(r'$\\frac{x - \\mu}{\\sigma}$')\n",
    "ax.set_ylabel(r'$p(x, \\mu=0, \\sigma=1)$')\n",
    "\n",
    "ax.set_yscale(\"log\")\n",
    "ax.legend()\n",
    "\n",
    "ax.grid()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cab3c81",
   "metadata": {},
   "source": [
    "That plot show us that values around less than about $2 \\sigma$ (note the use of the jargon in defining value in terms of $\\sigma$) are pretty common, but once we get past $2 \\sigma$, the odds of seeing a value out there if the data are truly random get to be very small very quickly.  The odds of seeing a fluctuation at the $6 \\sigma$ level at about 1 in 10 to the 9th, i.e., 1 in a billion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2678a92e",
   "metadata": {},
   "source": [
    "### Questions for discussion\n",
    "\n",
    "#### 3.1 Different fields have different conventions for what constitutes a \"statistically significant\" result.  In many fields a p-value of $< 0.05$ is considered significant.  In other fields, the threshold is $5 \\sigma$.  How much more unlikely is a $5 \\sigma$ fluctuation than one with a p-value of 0.05?   Why do you think that different fields might use such different conventions?  (It is ok to guess...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kipac_physics89L",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
