{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb356651",
   "metadata": {},
   "source": [
    "# Introduction to Propagation of Errors\n",
    "\n",
    "### Goals:\n",
    "\n",
    "1. To understand what we mean by \"propogation of errors\" and why it is important.\n",
    "2. To understand the equations governing propogation of errors.\n",
    "3. To apply those equations to a simple example, wherein we devise a really poor method of measuring the area of a table.\n",
    "\n",
    "### Timing\n",
    "\n",
    "1. Try to finish this notebook in 30-35 minutes\n",
    "\n",
    "### Question and Answer Template\n",
    "\n",
    "You can go to the link below, and do \"file\" -> \"make a copy\" to make yourself a google doc that you can use to fill in the answers to the question in this weeks notebooks.\n",
    "\n",
    "https://docs.google.com/document/d/1oEvpbIuJRRgsAXZ_E1DFt__JN3aqIly_LKNi146oe1Q/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14692ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cebcad",
   "metadata": {},
   "source": [
    "### Some functions we will use in this module\n",
    "\n",
    "| Function Name            | What it does |\n",
    "| - | - |\n",
    "|    rng.normal   | generates a random real number for a \"Gaussian\" or \"Normal\" distribution |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42cf30e",
   "metadata": {},
   "source": [
    "### Scientific Context\n",
    "\n",
    "Recall this figure illustrating Hubble's Law:\n",
    "\n",
    "<img src=\"figures/hubble_constant_far.jpg\" width=\"40%\"/>\n",
    "\n",
    "You may have noticed that each data point has horizontal error bars, indicating the uncertainty in distance, but no error bars for the velocity. \n",
    "\n",
    "The reason for this is that the velocity of distant objects can be measured quite accurately. This is done by measuring the \"redshift\" -- the increase in wavelength of the observed light from a source moving away from us. Modern sensors can measure these wavelength shifts with high resolution, leading to very small uncertainties in velocity (too small to show up on this plot!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea59e100",
   "metadata": {},
   "source": [
    "### The cosmic distance ladder\n",
    "\n",
    "Distances, on the other hand, are much harder to measure. As you can see in the Hubble plot, the uncertainties in measured distances can be large, and they tend to get larger as we look at more distant objects. \n",
    "\n",
    "The problem is that there is no single technique that can measure distances at all these different scales. Astronomers estimate distances mainly by using \"standard candles,\" which are objects that have a known luminosity. The distance of these objects can be inferred from the brightness that we observe on Earth.\n",
    "\n",
    "The difficulty with this method is that different types of standard candles are needed at different distance scales. Measuring a very distant object depends on accurately calibrating the standard candles at all the length scales in between! This is why the technique is called the \"distance ladder\" -- every time you go up a rung (distance scale) on the ladder, you have to calibrate using measurements from the previous rung. \n",
    "\n",
    "Some of the various techniques and standard candles used by astronomers are shown in the figure below. You can imagine how small errors can start to add up as you go farther up the ladder. This is the idea we'll be exploring in this notebook.\n",
    "\n",
    "<img src=\"figures/distance_ladder.png\" width=\"50%\"/>\n",
    "\n",
    "*By WilliamKF, TilmannR - File:Extragalactic_Distance_Ladder.svg, CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=69259966*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0f3171",
   "metadata": {},
   "source": [
    "### How not to measure the area of your desk or table\n",
    "\n",
    "Let's imagine that you need to estimate the area of the desk or table you are working at, but you don't have a ruler or other measuring device. Instead, by way of analogy to the cosmic distance ladder, you'll estimate the dimensions of some smaller objects, and then use those to calculate the area of the table. We'll assume your table is rectangular.\n",
    "\n",
    "1. Take a credit card or similar sized object (a phone or pen could also work, for example) from your wallet or bag.\n",
    "2. Estimate the length of the card, in centimeters. Let's call that $C$.  E.g., I'm using a debit card from my wallet and I estimate $C \\approx 8 {\\rm cm}$.\n",
    "3. Find a book, laptop or something else that is a few times longer than the card. Now measure the length of the book in terms of the length of the card.  Let's call that $B$.  E.g. I'm using a Moleskine notebook that was sitting on my desk, and I measured $B \\approx 2.5$ cards.\n",
    "4. Now measure the length and width of the table, using the book. Let's call these $l$ and $w$.  I found the dimensions of my desk to be $w \\approx 5.1$ and $l \\approx 3.8$ books.\n",
    "5. Now we do the math and estimate the area of the desk in centimeters. \n",
    "\n",
    "The width of the desk in cm is $(w \\times B \\times C)$, the length in cm is  $(l \\times B \\times C)$, so the area is\n",
    "\n",
    "$A = (w \\times B \\times C)(l \\times B \\times C) = w \\times l \\times B^2 \\times C^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb316bd",
   "metadata": {},
   "source": [
    "### Input your own measurments into the next cell\n",
    "\n",
    "The `_m` indicates that these are the quantities that we measured. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4fd06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_m = 8.\n",
    "B_m = 2.5\n",
    "l_m = 3.8\n",
    "w_m = 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5290653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's write a function to do that computation:\n",
    "def deskArea(w, l, B, C):\n",
    "    return w * l * B**2 * C**2\n",
    "\n",
    "A_m = deskArea(w_m, l_m, B_m, C_m)\n",
    "print(f\"Area of desk: {A_m:0.0f} cm^2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6185d6df",
   "metadata": {},
   "source": [
    "Of course, we should expect there to be error in our measurements, and these errors will have an effect on the final area that we calculate. Let's see how errors in the different factors can affect our final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07672602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if our estimate of the card size is off by 1 cm?\n",
    "A_new = deskArea(w_m, l_m, B_m, C_m+1)\n",
    "print(\"If C = C_m + 1:\")\n",
    "print(f\"    A = {A_new:0.0f} cm^2\")\n",
    "print(f\"    A = {(A_new / A_m):0.2f} * A_m\\n\")\n",
    "\n",
    "# What if we're 10% off in our measurement of one of the table dimensions?\n",
    "A_new2 = deskArea(w_m*1.1, l_m, B_m, C_m)\n",
    "print(\"If w = 1.1 * w_m:\")\n",
    "print(f\"    A = {A_new2:0.0f} cm^2\")\n",
    "print(f\"    A = {(A_new2/A_m):0.2f} * A_m\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7386cb10",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "##### E.1 Measure the area of your desk, and compute how much your estimate would change in both absolute and relative terms if:\n",
    "\n",
    "a. You had B_m wrong by 0.5 card lengths.\n",
    "\n",
    "b. If you had w_m wrong by 20\\%.\n",
    "\n",
    "Paste your work (including your values of l_m, w_m, B_m, C_m into the google doc template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a384dc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_new = deskArea(w_m, l_m, B_m+.5, C_m)\n",
    "print(\"If C = C_m + 1:\")\n",
    "print(f\"    A = {A_new:0.0f} cm^2\")\n",
    "print(f\"    A = {(A_new / A_m):0.2f} * A_m\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8dc4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_new = deskArea(w_m*1.2, l_m, B_m, C_m)\n",
    "print(\"If C = C_m + 1:\")\n",
    "print(f\"    A = {A_new:0.0f} cm^2\")\n",
    "print(f\"    A = {(A_new / A_m):0.2f} * A_m\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45216281",
   "metadata": {},
   "source": [
    "### We are actually just re-inventing calculus.\n",
    "\n",
    "What we are doing is estimating how much the value of a function changes when we change one of the input parameters.  \n",
    "\n",
    "That is exactly what a partial derivative is.\n",
    "\n",
    "For example, if we wanted to compute how much $A$ changes if we changed our estimate of $l$, we would get\n",
    "\n",
    "$\\Delta A_{l} = \\frac{\\partial A}{\\partial l} \\times \\delta l$\n",
    "\n",
    "Where $\\delta l$ is the change in our estimate of $l$, $\\Delta A_{l}$ is the change in A resulting from the change in $l$ and $\\frac{\\partial A}{\\partial l}$ is the partial derivative of $A$ with respect to $l$.\n",
    "\n",
    "Now here is an interesting point: when we compute the partial derivative of $A$ with respect to $l$, it just pulls a factor of $l$ out.\n",
    "\n",
    "$\\frac{\\partial A}{\\partial l} = w B^2 C^2$\n",
    "\n",
    "So, if compute the relative change in $A$ we see that a lot of things cancel out:\n",
    "\n",
    "$\\frac{\\Delta A_{l}}{A} = \\frac{w B^2 C^2 \\delta l}{w l B^2 C^2} = \\frac{\\delta l}{l}$\n",
    "\n",
    "**This is really not at all a suprising result.  All it is saying is that if your measurement of the length of the desk in terms of books were 10\\% higher, then your calculation of the area of the desk would also be 10\\% higher.** \n",
    "\n",
    "That is a pretty intuitive result by itself.  What we are going to do next is learn how to account for more complicated cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d36de9",
   "metadata": {},
   "source": [
    "### A complication\n",
    "\n",
    "In the example above, we don't actually know what $\\delta l$ (or $\\delta w$, $\\delta C$ and $\\delta B$) are.  They\n",
    "represent uncertainties.  \n",
    "\n",
    "However, for the purpose of the exercise, let's assume that $l \\pm \\delta l = l_{m} \\pm 0.10 l_{m}$  will cover most possible measurements of $l$ to see what the distribution of values of $A$ looks like.\n",
    "\n",
    "We are going to use capital $\\Delta$, e.g., $\\Delta l$ and $\\Delta A$ to refer to the changes with respect to the original that we see in specific trials, and lowercase $\\delta$, e.g., $\\delta l$ and $\\delta A$ to refer to the uncertainties we assign to quantities.  \n",
    "\n",
    "So, we use $l \\pm \\delta l$ to define a distribution of values of $l_{\\rm sim}$ which we then use to compute $\\Delta l = l_{\\rm sim} - l_{m}$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61184d3d",
   "metadata": {},
   "source": [
    "#### Simulating a bunch of measurements of l\n",
    "\n",
    "We are going to be simulating 10000 measurements, drawn from a normal distribution centered at $l_m$ and with a width of $0.1*l_m$.  \n",
    "\n",
    "This corresponds to an uncertainty of 10% on the measurement of $l$, i.e., $\\delta l/l = 0.10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbf8422",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8344a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will generate 10000 measurements drawn from a normal distribution \n",
    "# The distributon is centered at l_m and has standard deviation of 0.1*l_m\n",
    "l_sim = rng.normal(loc=l_m, scale=0.1*l_m, size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429fa37c",
   "metadata": {},
   "source": [
    "#### Then we plot them\n",
    "\n",
    "First as distribution of the simulated values (in the next cell).\n",
    "\n",
    "Then as a distribution of the relative change with respect to the orginal or central value (two cells down). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b038b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(l_sim, bins=np.linspace(0.6*l_m, 1.4*l_m, 81))\n",
    "plt.xlabel(\"Length of desk [in books]\")\n",
    "plt.ylabel(\"Simulated Trials [per bin]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa29e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((l_sim/l_m)-1, bins=np.linspace(-0.4, 0.4, 81))\n",
    "plt.xlabel(r'Fractional Change: $\\Delta l / l$')\n",
    "plt.ylabel(\"Simulated Trials [per bin]\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Fractional Change: ± {np.std((l_sim/l_m)-1):0.2f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bbd7b6",
   "metadata": {},
   "source": [
    "# Effect on Area measurement\n",
    "\n",
    "Now we are going to compute the distribution of measurements of the area $A$ we would get from those measurements of $l$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b927c8",
   "metadata": {},
   "source": [
    "### Case 1, effect of uncertainty in l on area\n",
    "\n",
    "Here we are just using the l_sim values we plotted above to simulate what would happen if we measured different values of l. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f21a66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are going to compute the resulting relative change in A\n",
    "A_sim_1 = deskArea(w_m, l_sim, B_m, C_m)\n",
    "dA_over_A_sim_1 = (A_sim_1 - A_m)/A_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0f07a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dA_over_A_sim_1, bins=np.linspace(-0.8, 0.8, 81))\n",
    "plt.xlabel(r'$\\Delta A / A$')\n",
    "plt.ylabel(r'Trials [per 0.02]')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Fractional Change: ± {np.std(dA_over_A_sim_1):0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8134aad7",
   "metadata": {},
   "source": [
    "### Case 2, effect of uncertainty in C on area\n",
    "\n",
    "In this case we are going to simulate what happens if we had used a different value of C, the length of the card we used to measure the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa581d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The distributon is centered at C_m and has standard deviation of 0.1*C_m\n",
    "C_sim = np.random.normal(loc=C_m, scale=0.1*C_m, size=10000)\n",
    "A_sim_2 = deskArea(w_m, l_m, B_m, C_sim)\n",
    "dA_over_A_sim_2 = (A_sim_2 - A_m)/A_m\n",
    "\n",
    "plt.hist(dA_over_A_sim_2, bins=np.linspace(-0.8, 0.8, 81))\n",
    "plt.xlabel(r'$\\Delta A / A$')\n",
    "plt.ylabel(r'Trials [per 0.02]')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Fractional Change: ± {np.std(dA_over_A_sim_2):0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed0eb80",
   "metadata": {},
   "source": [
    "### Case 3, effect of combined uncertainty in l and w on area\n",
    "\n",
    "In this case we are going to simulate what happens if we had found different values of both l and w, ie., the length and width of the desk, as measured in books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b67609",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_sim = rng.normal(loc=w_m, scale=0.1*w_m, size=10000)\n",
    "A_sim_3 = deskArea(w_sim, l_sim, B_m, C_m)\n",
    "dA_over_A_sim_3 = (A_sim_3 - A_m)/A_m\n",
    "\n",
    "plt.hist(dA_over_A_sim_3, bins=np.linspace(-0.8, 0.8, 81))\n",
    "plt.xlabel(r'$\\Delta A / A$')\n",
    "plt.ylabel(r'Trials [per 0.02]')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Fractional Change: ± {np.std(dA_over_A_sim_3):0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fd8eda",
   "metadata": {},
   "source": [
    "### Mathematical formulas\n",
    "\n",
    "For now, and for the next few weeks we are going to assume that the variables we are measuring are all independent of each other.  E.g. our measurement of $w$ did not somehow depend on $l$. For this particular example, that is almost certainly true. \n",
    "\n",
    "In general, for a quantity $f(x_i)$ that is a function of **_independent_** variables $x_i$, each of which has uncertainty $\\delta x_i$, the variance of $f$ is given by:\n",
    "$$\n",
    "\\sigma_f^{2}(x_i) = \\sum_i \\left(\\frac{\\partial f}{\\partial x_i} \\delta x_i\\right)^2\n",
    "$$\n",
    "where each partial derivative is evaluated at the mean values of $x_i$.\n",
    "\n",
    "In our case, $f = A$ is the area of the desk, and the $x_i$ are the things we measured, namely: $w$, $l$, $B$, and $C$.  \n",
    "Therefore, \n",
    "\n",
    "$\\sigma_A^2 = \\left(\\frac{\\partial A}{\\partial l} \\delta l\\right)^2 + \\left(\\frac{\\partial A}{\\partial w} \\delta w\\right)^2 + \\left(\\frac{\\partial A}{\\partial B} \\delta B\\right)^2 + \\left(\\frac{\\partial A}{\\partial C} \\delta C\\right)^2$\n",
    "\n",
    "This equation is the main reason that variances are so useful: for a calculated quantity that depends on input measurements with known uncertainties, it is straightforward to calculate the variance of that quantity. The square root of the variance will then tell you how much scatter you expect if you perform the measurement many times.\n",
    "\n",
    "Recall that in our case $A = w l B^2 C^2$. If we plug this in to the equation above and divide through by $A$, we find:\n",
    "\n",
    "$\\left(\\frac{\\sigma_A}{A}\\right)^2 = \\left(\\frac{\\delta l}{l}\\right)^2 + \\left(\\frac{\\delta w}{w}\\right)^2 + \\left(2 \\frac{\\delta B}{B}\\right)^2 + \\left(2 \\frac{\\delta C}{C}\\right)^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd3811b",
   "metadata": {},
   "source": [
    "The last formula tells us that in this case we can obtain an estimate of the relative uncertainty $\\frac{\\delta A}{A}$ by taking the square root of quantities related to the relative errors of each of the input measurments. Adding the squares of quantities and then taking the square root of the sum is often referred to as \"adding in quadrature.\"\n",
    "\n",
    "Given the general formula for $\\sigma^2_f$ above, we can write down a couple of handy rules for specific cases:\n",
    "\n",
    "1. If a quantity is the product of a bunch of measurements, you can add the *relative* errors of those measurements ($\\delta_i/x_i$) in quadrature to estimate the *relative* uncertainty on the quantity of interest $f$\n",
    "\n",
    "2. If a quantity is the sum of a bunch of measurements, you can add the *absolute* errors $\\delta_i$ of those measurements in quadrature to estimate the *absolute* uncertainty on the quantity of interest.\n",
    "\n",
    "These two rules are all you need to do error propagation in many, many cases. But if you have a more complicated formula, you can derive the error propagation dependence using the formula provided above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfd32d5",
   "metadata": {},
   "source": [
    "### Question for discussion\n",
    "\n",
    "#### 1.1 Connect the three figures we made above (cases 1, 2 and 3) to the formula for propagation of errors given just above.  Explain what exactly is being calculated in each case, and show that the numerical results we got match the formula. Explain in words the difference between the outcomes in the three cases.\n",
    "\n",
    "#### 1.2 In your own words, explain how we used random numbers to study the propagation of errors. What might be some limitations of this technique? What are some situations in which it would *not* be appropriate?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3155b469",
   "metadata": {},
   "source": [
    "# Example use case, computing the power output of a distant light source\n",
    "\n",
    "In astronomy and astrophysics, we can write down a formula for the \"energy flux\" i.e., the amount of energy captured in our detector in a given area in a given time, from a distant light source (i.e., a star or galaxy or other astronomical source):\n",
    "$$\n",
    "F_E = \\frac{\\hat{E}_{\\gamma}n_{\\gamma}}{A\\,\\eta\\, t}\n",
    "$$\n",
    "\n",
    "Where: \n",
    "\n",
    "$F_E$ is the \"energy flux\"\n",
    "\n",
    "$n_{\\gamma}$ is the number of photons we detected\n",
    "\n",
    "$\\hat{E}_{\\gamma}$ is the average photon energy\n",
    "\n",
    "$A$ is the area of the detector\n",
    "\n",
    "$\\eta$ is the total efficiency of the detector (including environmental effects such as scattering or absorption in the atmosphere)\n",
    "\n",
    "$t$ is the exposure or observation time, i.e., how long we pointed at the source.\n",
    "\n",
    "The units of energy flux are J m $^{-2}$ s $^{-1}$, i.e. energy per unit area per unit time.\n",
    "\n",
    "The total power from the source is the total energy per second crossing the surface of a sphere centered on the source.  \n",
    "$$\n",
    "P = 4 \\pi d^2  F_E = 4 \\pi d^2 \\, \\frac{\\hat{E}_{\\gamma}n_{\\gamma}}{A \\, \\eta \\, t}\n",
    "$$\n",
    "\n",
    "The units of power are Watts (Joules per second)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dbb822",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "#### Compute the relative uncertainty on the energy flux and the total power output by a source for two different observations.  Show your work!\n",
    "\n",
    "##### E.2  Observing the sun with a simple photodetector.  In this case let's assume that:\n",
    "\n",
    "1. The uncertainty on $n_{\\gamma}$ is about 2\\%. This estimate might come from studying the variation in repeated measurements.\n",
    "2. The uncertainty on $\\hat{E}_{\\gamma}$ is 3\\%, i.e., $\\frac{\\delta \\hat{E}_{\\gamma}}{\\hat{E}_{\\gamma}} = 0.03$\n",
    "3. The efficiency of the photodetector is only known to about 2\\%.  This number probably came from calibrating the photodetector with light of well-known brightness.\n",
    "\n",
    "All other quantities are known well enough that their uncertainty can be ignored.\n",
    "\n",
    "##### E.3 Observing the distant Gamma-ray pulsar Vela with a space-based telescope that is sensitive to gamma-rays. In this case let's assume:\n",
    "\n",
    "1. The uncertainty on the $n_{\\gamma}$ is about 3\\%.\n",
    "2. The uncertainty on $\\hat{E}_{\\gamma}$ is 5\\%.\n",
    "3. The efficiency of the telescope is only known to about 5\\%. \n",
    "4. The distance to Vela is only known to 20%.\n",
    "\n",
    "(Special note, while the sun emits light equally in all directions, we know that Vela does not, so using this equation for the power is wrong, but let's just ignore that for now.)\n",
    "\n",
    "\n",
    "### Question\n",
    "\n",
    "#### 2.1 Describe in words the results you got in the exercise. Are the total relative uncertainties about what you expect? Do these results suggest anything about when we might be able to ignore certain things when doing propagation of errors?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaabe88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
