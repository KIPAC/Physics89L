{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de609a45",
   "metadata": {},
   "source": [
    "# More Propagation of Uncertainties\n",
    "\n",
    "### Goals:\n",
    "\n",
    "1. To use simulated experiments to deepen our understanding of propagation of uncertainties.\n",
    "2. To use visual representations to further deepen our understanding of propagation of uncertainties.\n",
    "\n",
    "### Timing\n",
    "\n",
    "1. Try to finish this notebook in 30-35 minutes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f8e8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efad4821",
   "metadata": {},
   "source": [
    "| Function Name            | What it does |\n",
    "| - | - |\n",
    "|    numpy.expand_dims     | Adds a dimension to an array, useful for expanding two 1-D arrays into a 2-D array |\n",
    "| plt.imshow               | Makes a 2D-color plot by taking the values in a 2-D array to set a color scale |\n",
    "| plt.colorbar             | Adds a key corresponding to the color scale, e.g., when using plt.imshow |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20d1d4a",
   "metadata": {},
   "source": [
    "# Visual understanding of propagation of uncertainties\n",
    "\n",
    "### First example, how our estimate of $A$ depends on our measurement of $l$\n",
    "\n",
    "We are again going to simulate 10000 measurements of the length of the desk, assuming that they come from a Gaussian distribution that is centered on the value that we measured, but that have a standard deviation of 10% of that value.  \n",
    "\n",
    "Then we are going to see what happens to the distribution of outcomes, i.e., of the measurements of the area of the desk, with some further exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d6e5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate a random number generator with a fixed seed for\n",
    "## later reproducibility. \n",
    "rng = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8454351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rewrite the desk area function from the previous notebook.\n",
    "## Since each notebook has a dedicated kernel, we need to do this\n",
    "## as 'deskArea' is not a built-in function.\n",
    "def deskArea(w, l, B, C):\n",
    "    return w * l * B**2 * C**2\n",
    "\n",
    "## Use the values from our example, although you're welcome to \n",
    "## change to be consistent with what you measured.\n",
    "C_m = 8.\n",
    "B_m = 2.5\n",
    "l_m = 3.8\n",
    "w_m = 5.1\n",
    "\n",
    "## Test the function and compute the area of the desk.\n",
    "A_m = deskArea(w_m, l_m, B_m, C_m)\n",
    "print(f\"Area of desk: {A_m:0.0f} cm^2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45502ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function will simulate 10000 measurements with drawn \n",
    "## from a Normal distribution. The distribtuion is centered at \n",
    "## l_m and has standard deviation of 0.1*l_m\n",
    "l_sim = rng.normal(loc=l_m, scale=0.1*l_m, size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc1041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot our simulated data to make sure everything looks good\n",
    "plt.hist(l_sim, bins=np.linspace(0.6*l_m, 1.4*l_m, 81))\n",
    "plt.xlabel(\"Length of desk [in books]\")\n",
    "plt.ylabel(\"Simulated Trials [per bin]\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Measurements of desk length: {np.mean(l_sim):0.2f} ± {np.std(l_sim):0.2f} [books]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6baec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the relative change, again as a quick 'debugging' step\n",
    "## to make sure everything looks good and makes sense.\n",
    "plt.hist((l_sim/l_m)-1, bins=np.linspace(-0.4, 0.4, 81))\n",
    "plt.xlabel(r'Fractional Change: $\\Delta l / l$')\n",
    "plt.ylabel(\"Simulated Trials [per bin]\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Fractional Change: {np.mean((l_sim/l_m)-1):0.2f} ± {np.std((l_sim/l_m)-1):0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c0d48e",
   "metadata": {},
   "source": [
    "### Now, let's make a figure to show how $A$ depends on $l$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4799805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's make a grid of value of l that covers a wide range \n",
    "## around the value that we measured. These will be linearly \n",
    "## spaced values with a defined: start / end / number of points\n",
    "l_grid = l_m * np.linspace(0.6, 1.4, 81)\n",
    "\n",
    "## And let's compute the Area of each value of l\n",
    "A_from_l = deskArea(w_m, l_grid, B_m, C_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae3f35a",
   "metadata": {},
   "source": [
    "One of the arguments from the previous function call `l_grid` is an array instead of a single number! The function then returns another array instead of a number this it used to! How is it doing this?\n",
    "\n",
    "Python has \"dynamic typing\" which means that if it will try to do the mathematical operation that's asked, regardless of the type of data/object that it's using. For example, the `deskArea()` function was defined as:\n",
    "```\n",
    "def deskArea(w, l, B, C):\n",
    "    return w * l * B**2 * C**2\n",
    "```\n",
    "So if $l$ is an array of values (`l = [l0, l1, l2, ...]`), then it will do the math for each value of $l_i$ within the array. You could also have $w$ and $B$ and $C$ be arrays with the same length as $l$, then it will do the calculation index by index and return an array: `w = [w0 * l0 * B0**2 * C0**2, w1 * l1 * B1**2 * C1**2, ...]`\n",
    "\n",
    "Sometimes dynamic typing can be helpful (like in this example), and sometimes it can hide errors. Maybe one function is supposed to return a single value that becomes an input to a second function. If the first function is changed and starts returning arrays instead, the second function will try to use the argument and possibly produce strange/unexpected results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e858ed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we plot A verse l_grid\n",
    "plt.plot(l_grid, A_from_l)\n",
    "plt.ylabel(r'Area of desk [$cm^2$]')\n",
    "plt.xlabel(r'Length of desk [units of books]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584f6767",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the relative change in the area as a function of the\n",
    "## relative change in the length of the desk.\n",
    "plt.plot((l_grid/l_m)-1, (A_from_l/A_m)-1)\n",
    "plt.ylabel(r'Relative change in area $\\Delta A / A$')\n",
    "plt.xlabel(r'Relative change in length of desk $\\Delta l / l$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b540a1",
   "metadata": {},
   "source": [
    "### Questions for discussion:\n",
    "\n",
    "#### 3.1  Explain what is being shown in the two plots above.  How does this relate to the formula shown above, in particular the formula that includes the partial derivatives?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ab1a31",
   "metadata": {},
   "source": [
    "### Combining the sets of plots above.\n",
    "\n",
    "The first set of plots show the range of measurments we might expect for $l$ and $\\frac{\\delta}{l}$.  The second plot shows how $A$ changes if we change $l$.\n",
    "\n",
    "If we \"combine\" the two plots, we see the range of values that we might expect for $A$, given the uncertaintiy in $l$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e963989",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This command generates a 'figure' object, as well as two\n",
    "## plotting 'canvases' (axis0 and axis1) that we can use to\n",
    "## display all the data. There are a lot of options to this\n",
    "## subplots function giving a huge range of functionality,\n",
    "## but we just use it for a simple application here\n",
    "fig, (axis0, axis1) = plt.subplots(2, 1, figsize=(4,6), sharex=True)\n",
    "\n",
    "## On the top axis, plot the relative change in area as a\n",
    "## function of the relative change in length, together with a\n",
    "## histogram of the simulated data on the bottom axis.\n",
    "axis0.plot((l_grid/l_m)-1, (A_from_l/A_m)-1)\n",
    "axis1.hist((l_sim/l_m)-1, bins=(l_grid/l_m)-1)\n",
    "\n",
    "## Set unique ylabels for the plots, but a single x-axis label\n",
    "## for only the bottom plot (axis1).\n",
    "axis0.set_ylabel(r'Relative change in area $\\Delta A / A$')\n",
    "axis1.set_ylabel(\"Simulated Trials [per bin]\")\n",
    "axis1.set_xlabel(r'Relative change in length of desk $\\Delta l / l$')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457346cd",
   "metadata": {},
   "source": [
    "What we mean when we say that we \"combine\" the two plots, is that for each value of $\\frac{\\Delta l}{l}$ on the x-axis, the top plot tells us the resulting change $\\frac{\\Delta A}{A}$, while the bottom plot tells us how likely that value of $\\frac{\\Delta l}{l}$ is to occur.  \n",
    "\n",
    "So, we see that large changes in $l$ are less likely than small changes.  And the distribution of outcomes from our little simulation give us a sense of the scatter we would expect in $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287cc557",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the Area for the 10000 \"simulated\" measurements of l\n",
    "A_sim_1 = deskArea(w_m, l_sim, B_m, C_m)\n",
    "\n",
    "## Plot a histogram of the simulated areas to check and see what's\n",
    "## going on and that everything makes sense.\n",
    "plt.hist(A_sim_1, bins=81)\n",
    "plt.xlabel(r'$A [{\\rm cm}^2]$')\n",
    "plt.ylabel(r'Trials [per bin]')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Area of desk: {np.mean(A_sim_1):0.2f} ± {np.std(A_sim_1):0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b544ccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we are going to compute the resulting relative change in A\n",
    "dA_over_A_sim_1 = (A_sim_1 - A_m)/A_m\n",
    "\n",
    "## Plot a histogram of the simulated areas to investigate the \n",
    "## resultant spread from the simulated measurements of l.\n",
    "plt.hist(dA_over_A_sim_1, bins=np.linspace(-0.4, 0.4, 81))\n",
    "plt.xlabel(r'$\\Delta A / A$')\n",
    "plt.ylabel(r'Trials [per 0.02]')\n",
    "plt.show()\n",
    "\n",
    "## Compute the mean fractional change in the area A, as well as\n",
    "## the standard deviation of our \"measurements\" of A\n",
    "print(f\"Fractional Change: {np.mean(dA_over_A_sim_1):0.2f} ± {np.std(dA_over_A_sim_1):0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f743d43",
   "metadata": {},
   "source": [
    "## Second example: how our estimate of A depends on C\n",
    "\n",
    "Now we are going to repeat the exercise, but this time we are going to vary $C$, our estimate of the length of the card in cm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796d7003",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate an array of values for C, as well as a simulated\n",
    "## set of measurements of C drawn from a Normal distribution\n",
    "C_grid = C_m * np.linspace(0.6, 1.4, 81)\n",
    "C_sim = rng.normal(loc=C_m, scale=0.1*C_m, size=10000)\n",
    "A_from_C = deskArea(w_m, l_m, B_m, C_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df0a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the fractional change in area computed for each value \n",
    "## of C in our array as a function of the relative change in C\n",
    "plt.plot((C_grid / C_m)-1, (A_from_C / A_m)-1)\n",
    "plt.plot(np.linspace(-0.2,0.2,11), 2*np.linspace(-0.2,0.2,11), label=\"Tangent at zero\")\n",
    "plt.ylabel(r'Relative area of desk $\\Delta A / A$')\n",
    "plt.xlabel(r'Relative change in length of card $\\Delta C / C$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc23465",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the areas for the simulated measurements of C, and\n",
    "## compute teh fractional change relative to the mean value.\n",
    "A_sim_2 = deskArea(w_m, l_m, B_m, C_sim)\n",
    "dA_over_A_sim_2 = (A_sim_2 - A_m)/A_m\n",
    "\n",
    "## Plot a histogram of the simulated areas to investigate the \n",
    "## resultant spread from the simulated measurements of C.\n",
    "plt.hist(dA_over_A_sim_2, bins=np.linspace(-0.8, 0.8, 81))\n",
    "plt.xlabel(r'$\\Delta A / A$')\n",
    "plt.ylabel(r'Trials [per 0.05]')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Fractional Change: {np.mean(dA_over_A_sim_2):0.2f} ± {np.std(dA_over_A_sim_2):0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e3ee23",
   "metadata": {},
   "source": [
    "## Questions for discussion  \n",
    "\n",
    "#### 4.1 How can we interpret the two plots above?  What does it mean for our estimate of the uncertainty on $A$?  \n",
    "#### 4.2 Why does this differ from the results we got when we considered the variation in $A$ due to the variation in $l$?  \n",
    "#### 4.3 Why did we draw the tangent line on the figure a few cells up?   What does the tangent line correspond to in the equation for propagation of uncertainties?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d6f872",
   "metadata": {},
   "source": [
    "## A special case of uncertainty propagation\n",
    "\n",
    "Recall the exercise from the previous notebook about measuring the energy flux from the sun. We're going to focus on measuring $n_\\gamma$, the number of photons measured by our photodetector in the measurement time $t$.\n",
    "\n",
    "In order to write down the distribution for $n_\\gamma$, we need to know the mean value. Let's assume the energy flux on Earth is 1000 Watts/m $^2$ (our hypothetical experimenter doesn't know this yet, though!) \n",
    "\n",
    "We'll make the approximation that all of the photons have energy 3 eV (in reality, the photon energy from the sun follows a [blackbody distribution](https://en.wikipedia.org/wiki/Black-body_radiation)) and our photodetector is 1 mm $^2$ in area. This means we expect about $10^{15}$ photons to hit our detector every second.\n",
    "\n",
    "The number of photons hitting the detector every second will therefore follow a Poisson distribution with mean $\\lambda = 1e15$ photons/second. So the probability of measuring $k$ photons in one second is given by:\n",
    "$$\n",
    "P(k|\\lambda) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1678ce7b",
   "metadata": {},
   "source": [
    "### Experiment 1\n",
    "\n",
    "Let's simulate what a single set of measurements might look like. Imagine we leave our photodetector in the sun for 10000 seconds (about 3 hours) and record the number of photons counted in each second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd8a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate a bunch of samples from a poisson distribution\n",
    "## with a very large mean value (i.e. a 'high-frquency' process)\n",
    "sample1 = rng.poisson(1e15, 10000)\n",
    "\n",
    "## Given that the poisson distribution has variance equal to\n",
    "## the mean, generate some bin values based on this expectation\n",
    "bins = np.linspace(1e15-1e8, 1e15+1e8, 100)\n",
    "\n",
    "## Plot our sample just to see what's going on.\n",
    "plt.hist(sample1, bins)\n",
    "plt.xlabel(\"Number of photons observed\")\n",
    "plt.ylabel(\"Number of observations (per bin)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55073fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print the mean and standard deviation\n",
    "print(f\"Sample mean : {np.mean(sample1):0.3g}\")\n",
    "print(f\"Standard dev: {np.std(sample1):0.3g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9755fa5",
   "metadata": {},
   "source": [
    "### Question:\n",
    "\n",
    "##### 5.1 Do the sample mean and standard deviation match what you expect from the Poisson distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af156af",
   "metadata": {},
   "source": [
    "### Experiment 2\n",
    "\n",
    "Now imagine that we perform this measurement every day for 500 days. At the end of each day, we write down the mean and standard deviation of the dataset for that day. (We'll assume we are drawing from the same Poisson distribution every time, although in reality it will change depending on the Earth's position in its orbit.)\n",
    "\n",
    "At the end of the 500 days, we take the 500 means and plot them in a histogram. Here's what that would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea73ea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This will create a 500x10000 array, where each row represents \n",
    "## a single day's dataset with 10,000 data points\n",
    "sample_array = rng.poisson(1e15, size=(500, 10000))\n",
    "\n",
    "## You can use numpy to take means across specific axes of an\n",
    "## array, for instance, to average over the values from each of\n",
    "## the 500 days. The function below takes a mean across the first\n",
    "## axis and yield an array of 500 values, one for each day.\n",
    "means = np.mean(sample_array, axis=1)\n",
    "print(means.shape)\n",
    "\n",
    "## Print the mean of the sample means, and the standard deviation\n",
    "## of the sample means.\n",
    "print(f\"Mean of the sample means:         {np.mean(means):0.3g}\")\n",
    "print(f\"Standard dev of the sample means: {np.std(means):0.3g}\")\n",
    "\n",
    "## Note that the axes are different from the previous plot! This\n",
    "## time we're plotting a histogram of trials with a specific\n",
    "## number of photons rather than every 1-s recording period.\n",
    "bins = np.linspace(1e15-1e6, 1e15+1e6, 50)\n",
    "plt.hist(means, bins)\n",
    "plt.xlabel(\"Mean number of photons\")\n",
    "plt.ylabel(\"Number of trials (per bin)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55405ced",
   "metadata": {},
   "source": [
    "### Experiment 3\n",
    "\n",
    "After 500 days, we decide that we need more data. We buy 9 more photosensors (so now we have 10) and again record for 10,000 seconds each day, giving 100,000 samples per day. We do this for another 500 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a3de3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate the same type of dataset, but with 10 times as many \n",
    "## sensors, we have 10 times the data to deal with.\n",
    "sample_array = rng.poisson(1e15, size=(500, 100000))\n",
    "\n",
    "## Here we again take the mean across one axis of the sample_array,\n",
    "## giving us a 1D array of 500 values, one for each day.\n",
    "means = np.mean(sample_array, axis=1)\n",
    "\n",
    "## Print the mean of the sample means, and the standard deviation\n",
    "## of the sample means.\n",
    "print(f\"Mean of the sample means:         {np.mean(means):0.3g}\")\n",
    "print(f\"Standard dev of the sample means: {np.std(means):0.3g}\")\n",
    "\n",
    "bins = np.linspace(1e15-1e6, 1e15+1e6, 50)\n",
    "plt.hist(means, bins)\n",
    "plt.xlabel(\"Mean number of photons\")\n",
    "plt.ylabel(\"Number of trials (per bin)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b6e45d",
   "metadata": {},
   "source": [
    "### Experiment 4\n",
    "\n",
    "Someone is cleaning out the lab next door and finds some more photosensors. Now we have 100 sensors. If we again measure for 10,000 seconds per day, that gives us 1,000,000 samples per day. We do this for another 500 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851a7ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate the same type of dataset, but with 100 times as many \n",
    "## sensors, we have 100 times the data to deal with.\n",
    "sample_array = rng.poisson(1e15, size=(500, 1000000))\n",
    "\n",
    "## Here we again take the mean across one axis of the sample_array,\n",
    "## giving us a 1D array of 500 values, one for each day.\n",
    "means = np.mean(sample_array, axis=1)\n",
    "\n",
    "## Print the mean of the sample means, and the standard deviation\n",
    "## of the sample means.\n",
    "print(f\"Mean of the sample means:         {np.mean(means):0.3g}\")\n",
    "print(f\"Standard dev of the sample means: {np.std(means):0.3g}\")\n",
    "\n",
    "bins = np.linspace(1e15-1e6, 1e15+1e6, 50)\n",
    "plt.hist(means, bins)\n",
    "plt.xlabel(\"Mean number of photons\")\n",
    "plt.ylabel(\"Number of trials (per bin)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41814a7",
   "metadata": {},
   "source": [
    "### Question:\n",
    "\n",
    "##### 6.1 What do you notice about the shapes of the distributions for different numbers of observations taken each day? Is this what you expect?\n",
    "\n",
    "##### 6.2 What do you notice about the mean and standard deviation of each distribution? Be specific!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06decd2",
   "metadata": {},
   "source": [
    "### Comparing with theory\n",
    "\n",
    "Now let's compare the uncertainties we see in our simulation data with what we should expect to see. To do so, we have to think about what data we are really analyzing. For experiment 1, we have a bunch of observations in a single dataset. For experiments 2, 3 and 4, we have many datasets, and what we are really plotting is the mean of each dataset.\n",
    "\n",
    "How can we calculate the standard deviation we expect for each set of mean values? We'll start with the general formula for propagation of uncertainties:\n",
    "$$\n",
    "\\sigma_f^{2}(x_i) = \\sum_{i=1}^N \\left(\\frac{\\partial f}{\\partial x_i} \\delta x_i\\right)^2\n",
    "$$\n",
    "\n",
    "In this case, the function of interest $f$ is the *mean of the dataset*, which is given by:\n",
    "$$\n",
    "\\mu = \\frac{1}{N} \\sum_{i=1}^N x_i\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d584f9",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "\n",
    "##### 7.1 What are the partial derivatives $\\partial f / \\partial x_i$?\n",
    "\n",
    "##### 7.2 Plug in for the partial derivatives and simplify to show that $\\sigma_f = \\delta x_i / \\sqrt{N}$\n",
    "\n",
    "Hint: Keep in mind that we are drawing from the same distribution every time we make a measurement. What does this tell you about the values of $\\delta x_i$?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ff41ff",
   "metadata": {},
   "source": [
    "### Surprise! We've just derived the formula for the standard error on the mean.\n",
    "\n",
    "##### 7.3 Does this exercise contribute to your understanding of the standard error? If so, how? How does the standard error on the mean differ from the individual standard deviations of each measurement?\n",
    "\n",
    "##### 7.4 Plug in numbers to show that the means and standard errors that we found in the simulations above agree with the formula $\\sigma_f = \\delta x_i / \\sqrt{N}$. Please show your work!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
